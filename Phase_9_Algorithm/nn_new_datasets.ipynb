{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "#     mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "#     mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    rgb = rgb * (1. / 255)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.empty((0, 14400))\n",
    "    y = np.empty((0,1))\n",
    "    X_buffer = np.empty((0, 14400))\n",
    "    y_buffer = np.empty((0,1))\n",
    "    \n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "        \n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = preprocess(image)\n",
    "        image = image.reshape((14400))\n",
    "\n",
    "        X_buffer = np.append(X_buffer, [image], axis=0)\n",
    "        y_buffer = np.append(y_buffer, label)\n",
    "        \n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "        if recordCounter % 1000 == 0:\n",
    "            print(\"Merging\")\n",
    "            X = np.append(X, [X_buffer])\n",
    "            y = np.append(y, [y_buffer])\n",
    "            X_buffer = np.empty((0, 14400))\n",
    "            y_buffer = np.empty((0,1))\n",
    "    \n",
    "    print(\"Done\")        \n",
    "    X = np.append(X, [X_buffer])\n",
    "    y = np.append(y, y_buffer)\n",
    "    \n",
    "    X = X.reshape((recordCounter, 14400))\n",
    "    y = y.reshape((recordCounter,))\n",
    "    y = np.round(y / 6)\n",
    "    y = y + 7\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100->200->300->400->500->600->700->800->900->1000->Merging\n",
      "1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->Merging\n",
      "2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->Merging\n",
      "3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->Merging\n",
      "4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->Merging\n",
      "5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->Merging\n",
      "6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->Merging\n",
      "7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->Merging\n",
      "8100->8200->8300->8400->8500->8600->8700->8800->8900->9000->Merging\n",
      "9100->9200->9300->9400->9500->9600->9700->9800->9900->10000->Merging\n",
      "10100->10200->10300->10400->10500->10600->10700->10800->10900->11000->Merging\n",
      "11100->11200->11300->11400->11500->11600->11700->11800->11900->12000->Merging\n",
      "12100->12200->12300->12400->12500->12600->12700->12800->12900->13000->Merging\n",
      "13100->13200->13300->13400->13500->13600->13700->13800->13900->14000->Merging\n",
      "14100->14200->14300->14400->14500->14600->14700->14800->14900->15000->Merging\n",
      "15100->15200->15300->15400->15500->15600->15700->15800->15900->16000->Merging\n",
      "16100->16200->16300->16400->16500->16600->16700->16800->16900->17000->Merging\n",
      "17100->17200->17300->17400->17500->17600->17700->17800->17900->18000->Merging\n",
      "18100->18200->18300->18400->18500->18600->18700->18800->18900->19000->Merging\n",
      "19100->19200->19300->19400->19500->19600->19700->19800->19900->20000->Merging\n",
      "20100->20200->20300->20400->20500->20600->20700->20800->20900->21000->Merging\n",
      "21100->21200->21300->21400->21500->21600->21700->21800->21900->22000->Merging\n",
      "22100->22200->22300->22400->22500->22600->22700->22800->22900->23000->Merging\n",
      "23100->23200->23300->23400->23500->23600->23700->23800->23900->24000->Merging\n",
      "24100->24200->24300->24400->24500->24600->24700->24800->24900->25000->Merging\n",
      "25100->25200->25300->25400->25500->25600->25700->25800->25900->26000->Merging\n",
      "26100->26200->26300->26400->26500->26600->26700->26800->26900->27000->Merging\n",
      "27100->27200->27300->27400->27500->27600->27700->27800->27900->28000->Merging\n",
      "28100->28200->28300->28400->28500->28600->28700->28800->28900->29000->Merging\n",
      "29100->29200->29300->29400->29500->29600->29700->29800->29900->30000->Merging\n",
      "Done\n",
      "\n",
      "Val...\n",
      "100->200->300->400->500->600->700->800->900->1000->Merging\n",
      "1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->Merging\n",
      "2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->Merging\n",
      "3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->Merging\n",
      "4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->Merging\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays_norm.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays_norm.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.000e+00, 7.000e+00, 3.000e+00, 3.600e+02, 3.472e+03, 5.902e+03,\n",
       "        1.929e+03, 8.452e+03, 1.655e+03, 5.032e+03, 2.718e+03, 4.330e+02,\n",
       "        2.100e+01, 1.000e+01]),\n",
       " array([ 0.        ,  0.92857143,  1.85714286,  2.78571429,  3.71428571,\n",
       "         4.64285714,  5.57142857,  6.5       ,  7.42857143,  8.35714286,\n",
       "         9.28571429, 10.21428571, 11.14285714, 12.07142857, 13.        ]),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 14400], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 14400)\n",
      "[TL] DropoutLayer drop1: keep:0.800000 is_fix:False\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DropoutLayer drop2: keep:0.800000 is_fix:False\n",
      "[TL] DenseLayer  relu2: 2048 relu\n",
      "[TL] DenseLayer  relu3: 512 relu\n",
      "[TL] DenseLayer  output: 15 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu2')\n",
    "network = tl.layers.DenseLayer(network, 512, tf.nn.relu, name='relu3')\n",
    "network = tl.layers.DenseLayer(network, n_units=15, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (14400, 2048)      float32_ref (mean: -1.3793932339467574e-05, median: -2.9981927582412027e-05, std: 0.08796408027410507)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (2048, 2048)       float32_ref (mean: 5.985231473459862e-05, median: 0.0001428953546565026, std: 0.0879439190030098)   \n",
      "[TL]   param   3: relu2/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: relu3/W:0            (2048, 512)        float32_ref (mean: 6.991878763074055e-06, median: -4.2747455154312775e-05, std: 0.08785513043403625)   \n",
      "[TL]   param   5: relu3/b:0            (512,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   6: output/W:0           (512, 15)          float32_ref (mean: -0.00016323456657119095, median: -8.467522275168449e-05, std: 0.08784231543540955)   \n",
      "[TL]   param   7: output/b:0           (15,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 34746383\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: drop1/mul:0          (?, 14400)         float32\n",
      "[TL]   layer   1: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   2: drop2/mul:0          (?, 2048)          float32\n",
      "[TL]   layer   3: relu2/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   4: relu3/Relu:0         (?, 512)           float32\n",
      "[TL]   layer   5: output/Identity:0    (?, 15)            float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)\n",
    "cost_summ = tf.summary.scalar('cost', cost)\n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Setting up tensorboard ...\n",
      "[TL] [!] logs/ exists ...\n",
      "[TL] Finished! use $tensorboard --logdir=logs/ to start server\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 29.706169s\n",
      "[TL]    train loss: 1.680403\n",
      "[TL]    train acc: 0.507350\n",
      "[TL]    val loss: 1.662754\n",
      "[TL]    val acc: 0.483683\n",
      "[TL] Epoch 5 of 500 took 23.909987s\n",
      "[TL]    train loss: 1.229900\n",
      "[TL]    train acc: 0.519779\n",
      "[TL]    val loss: 1.213139\n",
      "[TL]    val acc: 0.518533\n",
      "[TL] Epoch 10 of 500 took 24.202945s\n",
      "[TL]    train loss: 1.159498\n",
      "[TL]    train acc: 0.568460\n",
      "[TL]    val loss: 1.142154\n",
      "[TL]    val acc: 0.564061\n",
      "[TL] Epoch 15 of 500 took 23.920088s\n",
      "[TL]    train loss: 1.124398\n",
      "[TL]    train acc: 0.569262\n",
      "[TL]    val loss: 1.105775\n",
      "[TL]    val acc: 0.573529\n",
      "[TL] Epoch 20 of 500 took 23.878526s\n",
      "[TL]    train loss: 1.120116\n",
      "[TL]    train acc: 0.575476\n",
      "[TL]    val loss: 1.111297\n",
      "[TL]    val acc: 0.576551\n",
      "[TL] Epoch 25 of 500 took 23.685187s\n",
      "[TL]    train loss: 1.068054\n",
      "[TL]    train acc: 0.595690\n",
      "[TL]    val loss: 1.070112\n",
      "[TL]    val acc: 0.579573\n",
      "[TL] Epoch 30 of 500 took 24.196584s\n",
      "[TL]    train loss: 1.056884\n",
      "[TL]    train acc: 0.595723\n",
      "[TL]    val loss: 1.065572\n",
      "[TL]    val acc: 0.587228\n",
      "[TL] Epoch 35 of 500 took 24.663327s\n",
      "[TL]    train loss: 1.030657\n",
      "[TL]    train acc: 0.590144\n",
      "[TL]    val loss: 1.034951\n",
      "[TL]    val acc: 0.596696\n",
      "[TL] Epoch 40 of 500 took 25.282398s\n",
      "[TL]    train loss: 1.016731\n",
      "[TL]    train acc: 0.608119\n",
      "[TL]    val loss: 1.046627\n",
      "[TL]    val acc: 0.583199\n",
      "[TL] Epoch 45 of 500 took 24.769845s\n",
      "[TL]    train loss: 1.005074\n",
      "[TL]    train acc: 0.606983\n",
      "[TL]    val loss: 1.062341\n",
      "[TL]    val acc: 0.566680\n",
      "[TL] Epoch 50 of 500 took 24.590779s\n",
      "[TL]    train loss: 0.974325\n",
      "[TL]    train acc: 0.617508\n",
      "[TL]    val loss: 1.038351\n",
      "[TL]    val acc: 0.586422\n",
      "[TL] Epoch 55 of 500 took 25.676391s\n",
      "[TL]    train loss: 0.975047\n",
      "[TL]    train acc: 0.624257\n",
      "[TL]    val loss: 1.064571\n",
      "[TL]    val acc: 0.580983\n",
      "[TL] Epoch 60 of 500 took 23.964807s\n",
      "[TL]    train loss: 0.941001\n",
      "[TL]    train acc: 0.625794\n",
      "[TL]    val loss: 1.012561\n",
      "[TL]    val acc: 0.596495\n",
      "[TL] Epoch 65 of 500 took 23.671057s\n",
      "[TL]    train loss: 0.939596\n",
      "[TL]    train acc: 0.628166\n",
      "[TL]    val loss: 1.031903\n",
      "[TL]    val acc: 0.590451\n",
      "[TL] Epoch 70 of 500 took 24.337869s\n",
      "[TL]    train loss: 0.922711\n",
      "[TL]    train acc: 0.635850\n",
      "[TL]    val loss: 1.031061\n",
      "[TL]    val acc: 0.586825\n",
      "[TL] Epoch 75 of 500 took 23.757276s\n",
      "[TL]    train loss: 0.917854\n",
      "[TL]    train acc: 0.643969\n",
      "[TL]    val loss: 1.032504\n",
      "[TL]    val acc: 0.585818\n",
      "[TL] Epoch 80 of 500 took 24.390032s\n",
      "[TL]    train loss: 0.898090\n",
      "[TL]    train acc: 0.648847\n",
      "[TL]    val loss: 1.026585\n",
      "[TL]    val acc: 0.589041\n",
      "[TL] Epoch 85 of 500 took 23.749142s\n",
      "[TL]    train loss: 0.885514\n",
      "[TL]    train acc: 0.646208\n",
      "[TL]    val loss: 1.037667\n",
      "[TL]    val acc: 0.578163\n",
      "[TL] Epoch 90 of 500 took 24.266795s\n",
      "[TL]    train loss: 0.884119\n",
      "[TL]    train acc: 0.654928\n",
      "[TL]    val loss: 1.009949\n",
      "[TL]    val acc: 0.602941\n",
      "[TL] Epoch 95 of 500 took 23.667916s\n",
      "[TL]    train loss: 0.865218\n",
      "[TL]    train acc: 0.651955\n",
      "[TL]    val loss: 0.995149\n",
      "[TL]    val acc: 0.600121\n",
      "[TL] Epoch 100 of 500 took 24.032227s\n",
      "[TL]    train loss: 0.857133\n",
      "[TL]    train acc: 0.665453\n",
      "[TL]    val loss: 1.023366\n",
      "[TL]    val acc: 0.582595\n",
      "[TL] Epoch 105 of 500 took 23.517686s\n",
      "[TL]    train loss: 0.845405\n",
      "[TL]    train acc: 0.666321\n",
      "[TL]    val loss: 1.029228\n",
      "[TL]    val acc: 0.578566\n",
      "[TL] Epoch 110 of 500 took 23.957062s\n",
      "[TL]    train loss: 0.832033\n",
      "[TL]    train acc: 0.671099\n",
      "[TL]    val loss: 1.009694\n",
      "[TL]    val acc: 0.589847\n",
      "[TL] Epoch 115 of 500 took 23.602745s\n",
      "[TL]    train loss: 0.837245\n",
      "[TL]    train acc: 0.672168\n",
      "[TL]    val loss: 0.999221\n",
      "[TL]    val acc: 0.596293\n",
      "[TL] Epoch 120 of 500 took 24.010828s\n",
      "[TL]    train loss: 0.811483\n",
      "[TL]    train acc: 0.681022\n",
      "[TL]    val loss: 1.022676\n",
      "[TL]    val acc: 0.585818\n",
      "[TL] Epoch 125 of 500 took 23.649868s\n",
      "[TL]    train loss: 0.815122\n",
      "[TL]    train acc: 0.679318\n",
      "[TL]    val loss: 1.025193\n",
      "[TL]    val acc: 0.580379\n",
      "[TL] Epoch 130 of 500 took 24.033911s\n",
      "[TL]    train loss: 0.804495\n",
      "[TL]    train acc: 0.674708\n",
      "[TL]    val loss: 0.991532\n",
      "[TL]    val acc: 0.599517\n",
      "[TL] Epoch 135 of 500 took 23.786229s\n",
      "[TL]    train loss: 0.789259\n",
      "[TL]    train acc: 0.688206\n",
      "[TL]    val loss: 0.990772\n",
      "[TL]    val acc: 0.589041\n",
      "[TL] Epoch 140 of 500 took 23.797556s\n",
      "[TL]    train loss: 0.786024\n",
      "[TL]    train acc: 0.687838\n",
      "[TL]    val loss: 1.003442\n",
      "[TL]    val acc: 0.590653\n",
      "[TL] Epoch 145 of 500 took 23.587704s\n",
      "[TL]    train loss: 0.775859\n",
      "[TL]    train acc: 0.693050\n",
      "[TL]    val loss: 1.028909\n",
      "[TL]    val acc: 0.580782\n",
      "[TL] Epoch 150 of 500 took 24.127356s\n",
      "[TL]    train loss: 0.757019\n",
      "[TL]    train acc: 0.699933\n",
      "[TL]    val loss: 1.000744\n",
      "[TL]    val acc: 0.587429\n",
      "[TL] Epoch 155 of 500 took 23.645858s\n",
      "[TL]    train loss: 0.767356\n",
      "[TL]    train acc: 0.695456\n",
      "[TL]    val loss: 1.042164\n",
      "[TL]    val acc: 0.584609\n",
      "[TL] Epoch 160 of 500 took 23.583833s\n",
      "[TL]    train loss: 0.760813\n",
      "[TL]    train acc: 0.697628\n",
      "[TL]    val loss: 1.012234\n",
      "[TL]    val acc: 0.582393\n",
      "[TL] Epoch 165 of 500 took 23.135850s\n",
      "[TL]    train loss: 0.750053\n",
      "[TL]    train acc: 0.703107\n",
      "[TL]    val loss: 1.033274\n",
      "[TL]    val acc: 0.577961\n",
      "[TL] Epoch 170 of 500 took 24.020358s\n",
      "[TL]    train loss: 0.727095\n",
      "[TL]    train acc: 0.710625\n",
      "[TL]    val loss: 1.033870\n",
      "[TL]    val acc: 0.584609\n",
      "[TL] Epoch 175 of 500 took 24.188400s\n",
      "[TL]    train loss: 0.729388\n",
      "[TL]    train acc: 0.710057\n",
      "[TL]    val loss: 1.038551\n",
      "[TL]    val acc: 0.575745\n",
      "[TL] Epoch 180 of 500 took 24.028194s\n",
      "[TL]    train loss: 0.714488\n",
      "[TL]    train acc: 0.716037\n",
      "[TL]    val loss: 1.029534\n",
      "[TL]    val acc: 0.583199\n",
      "[TL] Epoch 185 of 500 took 23.536041s\n",
      "[TL]    train loss: 0.722209\n",
      "[TL]    train acc: 0.718076\n",
      "[TL]    val loss: 0.999977\n",
      "[TL]    val acc: 0.592869\n",
      "[TL] Epoch 190 of 500 took 24.108084s\n",
      "[TL]    train loss: 0.713188\n",
      "[TL]    train acc: 0.717942\n",
      "[TL]    val loss: 1.080738\n",
      "[TL]    val acc: 0.573529\n",
      "[TL] Epoch 195 of 500 took 23.531554s\n",
      "[TL]    train loss: 0.701970\n",
      "[TL]    train acc: 0.724958\n",
      "[TL]    val loss: 1.024112\n",
      "[TL]    val acc: 0.592063\n",
      "[TL] Epoch 200 of 500 took 24.050496s\n",
      "[TL]    train loss: 0.689713\n",
      "[TL]    train acc: 0.725393\n",
      "[TL]    val loss: 1.028785\n",
      "[TL]    val acc: 0.578163\n",
      "[TL] Epoch 205 of 500 took 23.640845s\n",
      "[TL]    train loss: 0.681469\n",
      "[TL]    train acc: 0.728667\n",
      "[TL]    val loss: 1.027446\n",
      "[TL]    val acc: 0.580580\n",
      "[TL] Epoch 210 of 500 took 24.047534s\n",
      "[TL]    train loss: 0.682867\n",
      "[TL]    train acc: 0.727531\n",
      "[TL]    val loss: 1.055449\n",
      "[TL]    val acc: 0.581789\n",
      "[TL] Epoch 215 of 500 took 24.292710s\n",
      "[TL]    train loss: 0.668692\n",
      "[TL]    train acc: 0.731874\n",
      "[TL]    val loss: 1.048957\n",
      "[TL]    val acc: 0.581587\n",
      "[TL] Epoch 220 of 500 took 28.013358s\n",
      "[TL]    train loss: 0.667759\n",
      "[TL]    train acc: 0.725760\n",
      "[TL]    val loss: 1.075937\n",
      "[TL]    val acc: 0.582796\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2b33a501064b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m73\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=False, tensorboard_graph_vis=False)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(sess, network, train_op, cost, X_train, y_train, x, y_, acc, batch_size, n_epoch, print_freq, X_val, y_val, eval_train, tensorboard, tensorboard_epoch_freq, tensorboard_weight_histograms, tensorboard_graph_vis)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_drop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# enable noise layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mloss_ep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mn_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, \n",
    "    batch_size=73, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=True, \n",
    "    tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=False, tensorboard_graph_vis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model_norm.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model_norm.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model_norm.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x1da57a78048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model_norm.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "from IPython.display import IFrame\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = preprocess(i)\n",
    "            remoteImage = i.reshape((1, 14400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(55) + \",\" + str((direction[0] - 7) * 15)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"80\"\n",
       "            height=\"60\"\n",
       "            src=\"http://192.168.73.73:8080/?action=stream\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1da440539e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('http://192.168.73.73:8080/?action=stream', width=80, height=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
