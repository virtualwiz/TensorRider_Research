{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "#     mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "#     mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    rgb = rgb * (1. / 255)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.empty((0, 14400))\n",
    "    y = np.empty((0,1))\n",
    "    X_buffer = np.empty((0, 14400))\n",
    "    y_buffer = np.empty((0,1))\n",
    "    \n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "        \n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = preprocess(image)\n",
    "        image = image.reshape((14400))\n",
    "\n",
    "        X_buffer = np.append(X_buffer, [image], axis=0)\n",
    "        y_buffer = np.append(y_buffer, label)\n",
    "        \n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "        if recordCounter % 1000 == 0:\n",
    "            print(\"Merging\")\n",
    "            X = np.append(X, [X_buffer])\n",
    "            y = np.append(y, [y_buffer])\n",
    "            X_buffer = np.empty((0, 14400))\n",
    "            y_buffer = np.empty((0,1))\n",
    "    \n",
    "    print(\"Done\")        \n",
    "    X = np.append(X, [X_buffer])\n",
    "    y = np.append(y, y_buffer)\n",
    "    \n",
    "    X = X.reshape((recordCounter, 14400))\n",
    "    y = y.reshape((recordCounter,))\n",
    "    y = np.round(y / 6)\n",
    "    y = y + 7\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100->200->300->400->500->600->700->800->900->1000->Merging\n",
      "1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->Merging\n",
      "2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->Merging\n",
      "3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->Merging\n",
      "4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->Merging\n",
      "5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->Merging\n",
      "6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->Merging\n",
      "7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->Merging\n",
      "8100->8200->8300->8400->8500->8600->8700->8800->8900->9000->Merging\n",
      "9100->9200->9300->9400->9500->9600->9700->9800->9900->10000->Merging\n",
      "10100->10200->10300->10400->10500->10600->10700->10800->10900->11000->Merging\n",
      "11100->11200->11300->11400->11500->11600->11700->11800->11900->12000->Merging\n",
      "12100->12200->12300->12400->12500->12600->12700->12800->12900->13000->Merging\n",
      "13100->13200->13300->13400->13500->13600->13700->13800->13900->14000->Merging\n",
      "14100->14200->14300->14400->14500->14600->14700->14800->14900->15000->Merging\n",
      "15100->15200->15300->15400->15500->15600->15700->15800->15900->16000->Merging\n",
      "16100->16200->16300->16400->16500->16600->16700->16800->16900->17000->Merging\n",
      "17100->17200->17300->17400->17500->17600->17700->17800->17900->18000->Merging\n",
      "18100->18200->18300->18400->18500->18600->18700->18800->18900->19000->Merging\n",
      "19100->19200->19300->19400->19500->19600->19700->19800->19900->20000->Merging\n",
      "20100->20200->20300->20400->20500->20600->20700->20800->20900->21000->Merging\n",
      "21100->21200->21300->21400->21500->21600->21700->21800->21900->22000->Merging\n",
      "22100->22200->22300->22400->22500->22600->22700->22800->22900->23000->Merging\n",
      "23100->23200->23300->23400->23500->23600->23700->23800->23900->24000->Merging\n",
      "24100->24200->24300->24400->24500->24600->24700->24800->24900->25000->Merging\n",
      "25100->25200->25300->25400->25500->25600->25700->25800->25900->26000->Merging\n",
      "26100->26200->26300->26400->26500->26600->26700->26800->26900->27000->Merging\n",
      "27100->27200->27300->27400->27500->27600->27700->27800->27900->28000->Merging\n",
      "28100->28200->28300->28400->28500->28600->28700->28800->28900->29000->Merging\n",
      "29100->29200->29300->29400->29500->29600->29700->29800->29900->30000->Merging\n",
      "Done\n",
      "\n",
      "Val...\n",
      "100->200->300->400->500->600->700->800->900->1000->Merging\n",
      "1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->Merging\n",
      "2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->Merging\n",
      "3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->Merging\n",
      "4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->Merging\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays_norm.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays_norm.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.000e+00, 7.000e+00, 3.000e+00, 3.600e+02, 3.472e+03, 5.902e+03,\n",
       "        1.929e+03, 8.452e+03, 1.655e+03, 5.032e+03, 2.718e+03, 4.330e+02,\n",
       "        2.100e+01, 1.000e+01]),\n",
       " array([ 0.        ,  0.92857143,  1.85714286,  2.78571429,  3.71428571,\n",
       "         4.64285714,  5.57142857,  6.5       ,  7.42857143,  8.35714286,\n",
       "         9.28571429, 10.21428571, 11.14285714, 12.07142857, 13.        ]),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 14400], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 14400)\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DenseLayer  output: 15 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "network = tl.layers.DenseLayer(network, n_units=15, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (14400, 2048)      float32_ref (mean: 2.6911176973953843e-05, median: 2.246599797217641e-05, std: 0.0879698246717453)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: output/W:0           (2048, 15)         float32_ref (mean: -0.00039739918429404497, median: -2.266487354063429e-05, std: 0.08825226128101349)   \n",
      "[TL]   param   3: output/b:0           (15,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 29523983\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   1: output/Identity:0    (?, 15)            float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)\n",
    "cost_summ = tf.summary.scalar('cost', cost)\n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Setting up tensorboard ...\n",
      "[TL] [!] logs/ exists ...\n",
      "[TL] Finished! use $tensorboard --logdir=logs/ to start server\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 24.627733s\n",
      "[TL]    train loss: 2.120676\n",
      "[TL]    train acc: 0.497494\n",
      "[TL]    val loss: 2.280711\n",
      "[TL]    val acc: 0.455882\n",
      "[TL] Epoch 5 of 500 took 21.437964s\n",
      "[TL]    train loss: 2.049593\n",
      "[TL]    train acc: 0.466388\n",
      "[TL]    val loss: 2.050974\n",
      "[TL]    val acc: 0.441781\n",
      "[TL] Epoch 10 of 500 took 21.107062s\n",
      "[TL]    train loss: 1.240776\n",
      "[TL]    train acc: 0.591614\n",
      "[TL]    val loss: 1.465755\n",
      "[TL]    val acc: 0.573529\n",
      "[TL] Epoch 15 of 500 took 20.824369s\n",
      "[TL]    train loss: 1.203863\n",
      "[TL]    train acc: 0.591881\n",
      "[TL]    val loss: 1.312479\n",
      "[TL]    val acc: 0.568896\n",
      "[TL] Epoch 20 of 500 took 21.129656s\n",
      "[TL]    train loss: 1.096383\n",
      "[TL]    train acc: 0.624123\n",
      "[TL]    val loss: 1.322807\n",
      "[TL]    val acc: 0.595488\n",
      "[TL] Epoch 25 of 500 took 21.122957s\n",
      "[TL]    train loss: 1.209734\n",
      "[TL]    train acc: 0.586201\n",
      "[TL]    val loss: 1.308369\n",
      "[TL]    val acc: 0.579170\n",
      "[TL] Epoch 30 of 500 took 21.263053s\n",
      "[TL]    train loss: 0.849720\n",
      "[TL]    train acc: 0.666990\n",
      "[TL]    val loss: 1.125480\n",
      "[TL]    val acc: 0.563255\n",
      "[TL] Epoch 35 of 500 took 20.752422s\n",
      "[TL]    train loss: 0.882787\n",
      "[TL]    train acc: 0.656398\n",
      "[TL]    val loss: 1.087239\n",
      "[TL]    val acc: 0.589847\n",
      "[TL] Epoch 40 of 500 took 21.470802s\n",
      "[TL]    train loss: 0.893343\n",
      "[TL]    train acc: 0.652456\n",
      "[TL]    val loss: 1.198272\n",
      "[TL]    val acc: 0.572724\n",
      "[TL] Epoch 45 of 500 took 20.892493s\n",
      "[TL]    train loss: 0.888729\n",
      "[TL]    train acc: 0.649649\n",
      "[TL]    val loss: 1.201249\n",
      "[TL]    val acc: 0.540693\n",
      "[TL] Epoch 50 of 500 took 21.654227s\n",
      "[TL]    train loss: 0.847026\n",
      "[TL]    train acc: 0.666522\n",
      "[TL]    val loss: 1.190111\n",
      "[TL]    val acc: 0.577961\n",
      "[TL] Epoch 55 of 500 took 21.194133s\n",
      "[TL]    train loss: 0.849460\n",
      "[TL]    train acc: 0.671567\n",
      "[TL]    val loss: 1.175646\n",
      "[TL]    val acc: 0.597703\n",
      "[TL] Epoch 60 of 500 took 21.507188s\n",
      "[TL]    train loss: 0.765343\n",
      "[TL]    train acc: 0.688473\n",
      "[TL]    val loss: 1.108188\n",
      "[TL]    val acc: 0.570709\n",
      "[TL] Epoch 65 of 500 took 21.116644s\n",
      "[TL]    train loss: 0.769729\n",
      "[TL]    train acc: 0.690244\n",
      "[TL]    val loss: 1.110320\n",
      "[TL]    val acc: 0.604351\n",
      "[TL] Epoch 70 of 500 took 21.512626s\n",
      "[TL]    train loss: 0.742181\n",
      "[TL]    train acc: 0.697528\n",
      "[TL]    val loss: 1.122755\n",
      "[TL]    val acc: 0.593070\n",
      "[TL] Epoch 75 of 500 took 21.033257s\n",
      "[TL]    train loss: 0.932267\n",
      "[TL]    train acc: 0.637721\n",
      "[TL]    val loss: 1.260311\n",
      "[TL]    val acc: 0.602337\n",
      "[TL] Epoch 80 of 500 took 22.045786s\n",
      "[TL]    train loss: 0.759424\n",
      "[TL]    train acc: 0.690545\n",
      "[TL]    val loss: 1.169098\n",
      "[TL]    val acc: 0.556003\n",
      "[TL] Epoch 85 of 500 took 20.989676s\n",
      "[TL]    train loss: 0.999676\n",
      "[TL]    train acc: 0.644370\n",
      "[TL]    val loss: 1.357761\n",
      "[TL]    val acc: 0.570306\n",
      "[TL] Epoch 90 of 500 took 21.341487s\n",
      "[TL]    train loss: 0.809489\n",
      "[TL]    train acc: 0.680989\n",
      "[TL]    val loss: 1.257426\n",
      "[TL]    val acc: 0.572925\n",
      "[TL] Epoch 95 of 500 took 20.804588s\n",
      "[TL]    train loss: 0.726874\n",
      "[TL]    train acc: 0.710057\n",
      "[TL]    val loss: 1.095141\n",
      "[TL]    val acc: 0.594480\n",
      "[TL] Epoch 100 of 500 took 22.088969s\n",
      "[TL]    train loss: 0.656156\n",
      "[TL]    train acc: 0.739091\n",
      "[TL]    val loss: 1.078154\n",
      "[TL]    val acc: 0.583803\n",
      "[TL] Epoch 105 of 500 took 21.270980s\n",
      "[TL]    train loss: 0.718382\n",
      "[TL]    train acc: 0.711627\n",
      "[TL]    val loss: 1.241781\n",
      "[TL]    val acc: 0.541700\n",
      "[TL] Epoch 110 of 500 took 25.165224s\n",
      "[TL]    train loss: 0.642972\n",
      "[TL]    train acc: 0.742499\n",
      "[TL]    val loss: 1.113994\n",
      "[TL]    val acc: 0.590048\n",
      "[TL] Epoch 115 of 500 took 21.890619s\n",
      "[TL]    train loss: 0.658218\n",
      "[TL]    train acc: 0.736318\n",
      "[TL]    val loss: 1.098394\n",
      "[TL]    val acc: 0.619662\n",
      "[TL] Epoch 120 of 500 took 22.931757s\n",
      "[TL]    train loss: 0.676966\n",
      "[TL]    train acc: 0.718543\n",
      "[TL]    val loss: 1.137052\n",
      "[TL]    val acc: 0.586624\n",
      "[TL] Epoch 125 of 500 took 20.906907s\n",
      "[TL]    train loss: 0.620827\n",
      "[TL]    train acc: 0.747444\n",
      "[TL]    val loss: 1.116539\n",
      "[TL]    val acc: 0.605761\n",
      "[TL] Epoch 130 of 500 took 21.145731s\n",
      "[TL]    train loss: 0.613199\n",
      "[TL]    train acc: 0.757634\n",
      "[TL]    val loss: 1.107954\n",
      "[TL]    val acc: 0.581386\n",
      "[TL] Epoch 135 of 500 took 20.782599s\n",
      "[TL]    train loss: 0.669795\n",
      "[TL]    train acc: 0.715804\n",
      "[TL]    val loss: 1.232691\n",
      "[TL]    val acc: 0.601128\n",
      "[TL] Epoch 140 of 500 took 21.220568s\n",
      "[TL]    train loss: 0.685355\n",
      "[TL]    train acc: 0.721951\n",
      "[TL]    val loss: 1.189431\n",
      "[TL]    val acc: 0.572119\n",
      "[TL] Epoch 145 of 500 took 20.724694s\n",
      "[TL]    train loss: 0.610527\n",
      "[TL]    train acc: 0.755630\n",
      "[TL]    val loss: 1.255026\n",
      "[TL]    val acc: 0.553183\n",
      "[TL] Epoch 150 of 500 took 21.314863s\n",
      "[TL]    train loss: 0.599048\n",
      "[TL]    train acc: 0.759673\n",
      "[TL]    val loss: 1.145078\n",
      "[TL]    val acc: 0.581386\n",
      "[TL] Epoch 155 of 500 took 20.807548s\n",
      "[TL]    train loss: 0.578709\n",
      "[TL]    train acc: 0.770297\n",
      "[TL]    val loss: 1.198880\n",
      "[TL]    val acc: 0.573932\n",
      "[TL] Epoch 160 of 500 took 21.191241s\n",
      "[TL]    train loss: 0.604201\n",
      "[TL]    train acc: 0.748146\n",
      "[TL]    val loss: 1.180940\n",
      "[TL]    val acc: 0.572522\n",
      "[TL] Epoch 165 of 500 took 20.842548s\n",
      "[TL]    train loss: 0.543233\n",
      "[TL]    train acc: 0.786001\n",
      "[TL]    val loss: 1.147503\n",
      "[TL]    val acc: 0.594279\n",
      "[TL] Epoch 170 of 500 took 21.113419s\n",
      "[TL]    train loss: 0.601215\n",
      "[TL]    train acc: 0.755329\n",
      "[TL]    val loss: 1.350213\n",
      "[TL]    val acc: 0.544923\n",
      "[TL] Epoch 175 of 500 took 21.255368s\n",
      "[TL]    train loss: 0.525732\n",
      "[TL]    train acc: 0.790311\n",
      "[TL]    val loss: 1.185394\n",
      "[TL]    val acc: 0.596092\n",
      "[TL] Epoch 180 of 500 took 21.170732s\n",
      "[TL]    train loss: 0.551951\n",
      "[TL]    train acc: 0.783695\n",
      "[TL]    val loss: 1.211452\n",
      "[TL]    val acc: 0.581386\n",
      "[TL] Epoch 185 of 500 took 20.797325s\n",
      "[TL]    train loss: 0.554708\n",
      "[TL]    train acc: 0.775610\n",
      "[TL]    val loss: 1.279552\n",
      "[TL]    val acc: 0.570508\n",
      "[TL] Epoch 190 of 500 took 21.273051s\n",
      "[TL]    train loss: 0.563973\n",
      "[TL]    train acc: 0.771066\n",
      "[TL]    val loss: 1.261201\n",
      "[TL]    val acc: 0.573328\n",
      "[TL] Epoch 195 of 500 took 20.802252s\n",
      "[TL]    train loss: 0.505827\n",
      "[TL]    train acc: 0.797761\n",
      "[TL]    val loss: 1.273341\n",
      "[TL]    val acc: 0.578969\n",
      "[TL] Epoch 200 of 500 took 21.163155s\n",
      "[TL]    train loss: 0.512774\n",
      "[TL]    train acc: 0.796124\n",
      "[TL]    val loss: 1.176398\n",
      "[TL]    val acc: 0.596898\n",
      "[TL] Epoch 205 of 500 took 20.896270s\n",
      "[TL]    train loss: 0.539625\n",
      "[TL]    train acc: 0.785099\n",
      "[TL]    val loss: 1.357457\n",
      "[TL]    val acc: 0.553787\n",
      "[TL] Epoch 210 of 500 took 21.329623s\n",
      "[TL]    train loss: 0.599133\n",
      "[TL]    train acc: 0.759038\n",
      "[TL]    val loss: 1.511682\n",
      "[TL]    val acc: 0.552377\n",
      "[TL] Epoch 215 of 500 took 20.924083s\n",
      "[TL]    train loss: 0.488634\n",
      "[TL]    train acc: 0.804277\n",
      "[TL]    val loss: 1.219339\n",
      "[TL]    val acc: 0.599919\n",
      "[TL] Epoch 220 of 500 took 21.203288s\n",
      "[TL]    train loss: 0.458619\n",
      "[TL]    train acc: 0.820247\n",
      "[TL]    val loss: 1.285020\n",
      "[TL]    val acc: 0.576753\n",
      "[TL] Epoch 225 of 500 took 20.792831s\n",
      "[TL]    train loss: 0.476764\n",
      "[TL]    train acc: 0.811861\n",
      "[TL]    val loss: 1.381271\n",
      "[TL]    val acc: 0.567687\n",
      "[TL] Epoch 230 of 500 took 21.286206s\n",
      "[TL]    train loss: 0.442966\n",
      "[TL]    train acc: 0.830772\n",
      "[TL]    val loss: 1.295805\n",
      "[TL]    val acc: 0.587429\n",
      "[TL] Epoch 235 of 500 took 20.808822s\n",
      "[TL]    train loss: 0.458945\n",
      "[TL]    train acc: 0.816505\n",
      "[TL]    val loss: 1.342648\n",
      "[TL]    val acc: 0.581185\n",
      "[TL] Epoch 240 of 500 took 21.168986s\n",
      "[TL]    train loss: 0.470905\n",
      "[TL]    train acc: 0.808052\n",
      "[TL]    val loss: 1.376372\n",
      "[TL]    val acc: 0.586221\n",
      "[TL] Epoch 245 of 500 took 20.845957s\n",
      "[TL]    train loss: 0.484017\n",
      "[TL]    train acc: 0.801771\n",
      "[TL]    val loss: 1.511117\n",
      "[TL]    val acc: 0.553989\n",
      "[TL] Epoch 250 of 500 took 21.177804s\n",
      "[TL]    train loss: 0.425889\n",
      "[TL]    train acc: 0.831574\n",
      "[TL]    val loss: 1.301778\n",
      "[TL]    val acc: 0.602941\n",
      "[TL] Epoch 255 of 500 took 20.838804s\n",
      "[TL]    train loss: 0.443795\n",
      "[TL]    train acc: 0.819245\n",
      "[TL]    val loss: 1.388052\n",
      "[TL]    val acc: 0.580983\n",
      "[TL] Epoch 260 of 500 took 21.331047s\n",
      "[TL]    train loss: 0.435645\n",
      "[TL]    train acc: 0.826662\n",
      "[TL]    val loss: 1.379234\n",
      "[TL]    val acc: 0.571313\n",
      "[TL] Epoch 265 of 500 took 20.845922s\n",
      "[TL]    train loss: 0.434973\n",
      "[TL]    train acc: 0.825159\n",
      "[TL]    val loss: 1.355632\n",
      "[TL]    val acc: 0.580580\n",
      "[TL] Epoch 270 of 500 took 20.590429s\n",
      "[TL]    train loss: 0.441447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]    train acc: 0.829569\n",
      "[TL]    val loss: 1.374625\n",
      "[TL]    val acc: 0.575342\n",
      "[TL] Epoch 275 of 500 took 20.292208s\n",
      "[TL]    train loss: 0.404721\n",
      "[TL]    train acc: 0.835984\n",
      "[TL]    val loss: 1.474006\n",
      "[TL]    val acc: 0.582796\n",
      "[TL] Epoch 280 of 500 took 20.758626s\n",
      "[TL]    train loss: 0.457230\n",
      "[TL]    train acc: 0.817741\n",
      "[TL]    val loss: 1.458054\n",
      "[TL]    val acc: 0.598106\n",
      "[TL] Epoch 285 of 500 took 20.315818s\n",
      "[TL]    train loss: 0.420323\n",
      "[TL]    train acc: 0.836318\n",
      "[TL]    val loss: 1.506286\n",
      "[TL]    val acc: 0.571313\n",
      "[TL] Epoch 290 of 500 took 20.814420s\n",
      "[TL]    train loss: 0.455539\n",
      "[TL]    train acc: 0.817908\n",
      "[TL]    val loss: 1.644323\n",
      "[TL]    val acc: 0.525584\n",
      "[TL] Epoch 295 of 500 took 20.302528s\n",
      "[TL]    train loss: 0.374920\n",
      "[TL]    train acc: 0.853425\n",
      "[TL]    val loss: 1.390168\n",
      "[TL]    val acc: 0.592264\n",
      "[TL] Epoch 300 of 500 took 20.522734s\n",
      "[TL]    train loss: 0.358699\n",
      "[TL]    train acc: 0.866455\n",
      "[TL]    val loss: 1.453016\n",
      "[TL]    val acc: 0.562651\n",
      "[TL] Epoch 305 of 500 took 21.298628s\n",
      "[TL]    train loss: 0.402491\n",
      "[TL]    train acc: 0.834480\n",
      "[TL]    val loss: 1.455596\n",
      "[TL]    val acc: 0.602135\n",
      "[TL] Epoch 310 of 500 took 21.257028s\n",
      "[TL]    train loss: 0.345442\n",
      "[TL]    train acc: 0.869161\n",
      "[TL]    val loss: 1.445847\n",
      "[TL]    val acc: 0.580782\n",
      "[TL] Epoch 315 of 500 took 20.917757s\n",
      "[TL]    train loss: 0.352293\n",
      "[TL]    train acc: 0.859405\n",
      "[TL]    val loss: 1.575279\n",
      "[TL]    val acc: 0.594279\n",
      "[TL] Epoch 320 of 500 took 21.412922s\n",
      "[TL]    train loss: 0.331831\n",
      "[TL]    train acc: 0.875476\n",
      "[TL]    val loss: 1.478207\n",
      "[TL]    val acc: 0.581386\n",
      "[TL] Epoch 325 of 500 took 20.930617s\n",
      "[TL]    train loss: 0.330189\n",
      "[TL]    train acc: 0.874908\n",
      "[TL]    val loss: 1.446305\n",
      "[TL]    val acc: 0.585415\n",
      "[TL] Epoch 330 of 500 took 21.356222s\n",
      "[TL]    train loss: 0.321846\n",
      "[TL]    train acc: 0.880187\n",
      "[TL]    val loss: 1.484958\n",
      "[TL]    val acc: 0.564464\n",
      "[TL] Epoch 335 of 500 took 20.779613s\n",
      "[TL]    train loss: 0.346396\n",
      "[TL]    train acc: 0.863916\n",
      "[TL]    val loss: 1.553125\n",
      "[TL]    val acc: 0.573328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2b33a501064b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m73\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=False, tensorboard_graph_vis=False)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(sess, network, train_op, cost, X_train, y_train, x, y_, acc, batch_size, n_epoch, print_freq, X_val, y_val, eval_train, tensorboard, tensorboard_epoch_freq, tensorboard_weight_histograms, tensorboard_graph_vis)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_drop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# enable noise layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mloss_ep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mn_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1104\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, \n",
    "    batch_size=73, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=True, \n",
    "    tensorboard=True, tensorboard_epoch_freq=5, tensorboard_weight_histograms=False, tensorboard_graph_vis=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model_norm.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model_norm.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model_norm.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x287fdecdef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model_norm.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = preprocess(i)\n",
    "            remoteImage = i.reshape((1, 14400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(40) + \",\" + str((direction[0] - 7) * 11)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
