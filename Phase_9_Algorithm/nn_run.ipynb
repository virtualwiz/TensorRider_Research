{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mono(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    # mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.zeros(4800)\n",
    "    y = np.zeros(1)\n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "\n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = rgb2mono(image)\n",
    "        image = image.reshape((4800))\n",
    "\n",
    "        X = np.vstack((X,image))\n",
    "        y = np.append(y,label)\n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "\n",
    "    y = y.reshape((recordCounter + 1,))\n",
    "#     y = np.round(y / 7) #Downsampling\n",
    "#     y = y + 6\n",
    "    y = np.round(y / 12)\n",
    "    y = y + 3\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")\n",
    "testIterator = tf.python_io.tf_record_iterator(path=\"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n",
      "100->"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->8100->8200->8300->8400->8500->8600->8700->8800->8900->9000->9100->9200->9300->9400->9500->9600->9700->9800->9900->10000->10100->10200->10300->10400->10500->10600->10700->10800->10900->11000->11100->11200->11300->11400->11500->11600->11700->11800->11900->12000->12100->12200->12300->12400->12500->12600->12700->12800->12900->13000->13100->13200->13300->13400->13500->\n",
      "Val...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->\n",
      "Test...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)\n",
    "print(\"\\nTest...\")\n",
    "X_test, y_test = prepareDataArrays(testIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val, xt = X_test, yt = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]\n",
    "X_test = npRecall[\"xt\"]\n",
    "y_test = npRecall[\"yt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.930e+02, 0.000e+00, 4.565e+03, 0.000e+00, 4.786e+03, 0.000e+00,\n",
       "        3.352e+03, 0.000e+00, 3.960e+02, 3.000e+00]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "# plt.hist(y_val)\n",
    "# plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 4800], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 4800)\n",
      "[TL] DropoutLayer drop1: keep:0.800000 is_fix:False\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DenseLayer  relu2: 1024 relu\n",
      "[TL] DenseLayer  relu3: 1024 relu\n",
      "[TL] DenseLayer  output: 7 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu2')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu3')\n",
    "# network = tl.layers.DenseLayer(network, 512, tf.nn.relu, name='relu4')\n",
    "# network = tl.layers.DenseLayer(network, n_units=13, act=tf.identity, name='output')\n",
    "network = tl.layers.DenseLayer(network, n_units=7, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (4800, 2048)       float32_ref (mean: 2.2490896753879497e-06, median: 1.707380943116732e-05, std: 0.08796518296003342)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (2048, 1024)       float32_ref (mean: -7.237248064484447e-05, median: -9.516134741716087e-05, std: 0.08792534470558167)   \n",
      "[TL]   param   3: relu2/b:0            (1024,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: relu3/W:0            (1024, 1024)       float32_ref (mean: -7.022503996267915e-05, median: -8.054064528550953e-05, std: 0.08805258572101593)   \n",
      "[TL]   param   5: relu3/b:0            (1024,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   6: output/W:0           (1024, 7)          float32_ref (mean: 2.5835088308667764e-05, median: -0.001053034677170217, std: 0.08831722289323807)   \n",
      "[TL]   param   7: output/b:0           (7,)               float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 12987399\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: drop1/mul:0          (?, 4800)          float32\n",
      "[TL]   layer   1: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   2: relu2/Relu:0         (?, 1024)          float32\n",
      "[TL]   layer   3: relu3/Relu:0         (?, 1024)          float32\n",
      "[TL]   layer   4: output/Identity:0    (?, 7)             float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)  \n",
    "cost_summ = tf.summary.scalar('cost', cost)  \n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 2.785300s\n",
      "[TL]    val loss: 609.712210\n",
      "[TL]    val acc: 0.696667\n",
      "[TL] Epoch 5 of 500 took 2.384999s\n",
      "[TL]    val loss: 189.802146\n",
      "[TL]    val acc: 0.708889\n",
      "[TL] Epoch 10 of 500 took 2.306269s\n",
      "[TL]    val loss: 154.464518\n",
      "[TL]    val acc: 0.697037\n",
      "[TL] Epoch 15 of 500 took 2.317661s\n",
      "[TL]    val loss: 80.050606\n",
      "[TL]    val acc: 0.722593\n",
      "[TL] Epoch 20 of 500 took 2.398335s\n",
      "[TL]    val loss: 59.174184\n",
      "[TL]    val acc: 0.627037\n",
      "[TL] Epoch 25 of 500 took 2.381282s\n",
      "[TL]    val loss: 34.147177\n",
      "[TL]    val acc: 0.728148\n",
      "[TL] Epoch 30 of 500 took 2.306662s\n",
      "[TL]    val loss: 28.615673\n",
      "[TL]    val acc: 0.723333\n",
      "[TL] Epoch 35 of 500 took 2.296301s\n",
      "[TL]    val loss: 20.589285\n",
      "[TL]    val acc: 0.727037\n",
      "[TL] Epoch 40 of 500 took 2.287117s\n",
      "[TL]    val loss: 18.342812\n",
      "[TL]    val acc: 0.677037\n",
      "[TL] Epoch 45 of 500 took 2.305817s\n",
      "[TL]    val loss: 33.733920\n",
      "[TL]    val acc: 0.567778\n",
      "[TL] Epoch 50 of 500 took 2.266107s\n",
      "[TL]    val loss: 27.103077\n",
      "[TL]    val acc: 0.541111\n",
      "[TL] Epoch 55 of 500 took 2.319214s\n",
      "[TL]    val loss: 18.636360\n",
      "[TL]    val acc: 0.575926\n",
      "[TL] Epoch 60 of 500 took 2.284681s\n",
      "[TL]    val loss: 18.893605\n",
      "[TL]    val acc: 0.653333\n",
      "[TL] Epoch 65 of 500 took 2.329715s\n",
      "[TL]    val loss: 15.654721\n",
      "[TL]    val acc: 0.658889\n",
      "[TL] Epoch 70 of 500 took 2.296458s\n",
      "[TL]    val loss: 9.723646\n",
      "[TL]    val acc: 0.630000\n",
      "[TL] Epoch 75 of 500 took 2.341221s\n",
      "[TL]    val loss: 13.176696\n",
      "[TL]    val acc: 0.683333\n",
      "[TL] Epoch 80 of 500 took 2.263768s\n",
      "[TL]    val loss: 14.353830\n",
      "[TL]    val acc: 0.641481\n",
      "[TL] Epoch 85 of 500 took 2.292115s\n",
      "[TL]    val loss: 13.353057\n",
      "[TL]    val acc: 0.734074\n",
      "[TL] Epoch 90 of 500 took 2.352568s\n",
      "[TL]    val loss: 14.816625\n",
      "[TL]    val acc: 0.636296\n",
      "[TL] Epoch 95 of 500 took 2.320162s\n",
      "[TL]    val loss: 13.881043\n",
      "[TL]    val acc: 0.682963\n",
      "[TL] Epoch 100 of 500 took 2.319495s\n",
      "[TL]    val loss: 9.944493\n",
      "[TL]    val acc: 0.726296\n",
      "[TL] Epoch 105 of 500 took 2.288636s\n",
      "[TL]    val loss: 18.476178\n",
      "[TL]    val acc: 0.550741\n",
      "[TL] Epoch 110 of 500 took 2.321293s\n",
      "[TL]    val loss: 14.637181\n",
      "[TL]    val acc: 0.613704\n",
      "[TL] Epoch 115 of 500 took 2.296992s\n",
      "[TL]    val loss: 12.629881\n",
      "[TL]    val acc: 0.486296\n",
      "[TL] Epoch 120 of 500 took 2.334492s\n",
      "[TL]    val loss: 8.474087\n",
      "[TL]    val acc: 0.598519\n",
      "[TL] Epoch 125 of 500 took 2.259504s\n",
      "[TL]    val loss: 10.282799\n",
      "[TL]    val acc: 0.727037\n",
      "[TL] Epoch 130 of 500 took 2.295179s\n",
      "[TL]    val loss: 8.009514\n",
      "[TL]    val acc: 0.730741\n",
      "[TL] Epoch 135 of 500 took 2.280228s\n",
      "[TL]    val loss: 10.307179\n",
      "[TL]    val acc: 0.512963\n",
      "[TL] Epoch 140 of 500 took 2.368520s\n",
      "[TL]    val loss: 13.580896\n",
      "[TL]    val acc: 0.457778\n",
      "[TL] Epoch 145 of 500 took 2.303013s\n",
      "[TL]    val loss: 8.508249\n",
      "[TL]    val acc: 0.715926\n",
      "[TL] Epoch 150 of 500 took 2.312511s\n",
      "[TL]    val loss: 8.773658\n",
      "[TL]    val acc: 0.555556\n",
      "[TL] Epoch 155 of 500 took 2.303930s\n",
      "[TL]    val loss: 8.698612\n",
      "[TL]    val acc: 0.728889\n",
      "[TL] Epoch 160 of 500 took 2.280822s\n",
      "[TL]    val loss: 6.442327\n",
      "[TL]    val acc: 0.725556\n",
      "[TL] Epoch 165 of 500 took 2.298107s\n",
      "[TL]    val loss: 8.614066\n",
      "[TL]    val acc: 0.488519\n",
      "[TL] Epoch 170 of 500 took 2.347396s\n",
      "[TL]    val loss: 6.985193\n",
      "[TL]    val acc: 0.711852\n",
      "[TL] Epoch 175 of 500 took 2.441586s\n",
      "[TL]    val loss: 5.278984\n",
      "[TL]    val acc: 0.727778\n",
      "[TL] Epoch 180 of 500 took 2.422482s\n",
      "[TL]    val loss: 6.775482\n",
      "[TL]    val acc: 0.703333\n",
      "[TL] Epoch 185 of 500 took 2.438832s\n",
      "[TL]    val loss: 5.315945\n",
      "[TL]    val acc: 0.675556\n",
      "[TL] Epoch 190 of 500 took 2.305486s\n",
      "[TL]    val loss: 5.636497\n",
      "[TL]    val acc: 0.702222\n",
      "[TL] Epoch 195 of 500 took 2.379966s\n",
      "[TL]    val loss: 6.313301\n",
      "[TL]    val acc: 0.649259\n",
      "[TL] Epoch 200 of 500 took 2.438302s\n",
      "[TL]    val loss: 8.318173\n",
      "[TL]    val acc: 0.481111\n",
      "[TL] Epoch 205 of 500 took 2.329914s\n",
      "[TL]    val loss: 5.474695\n",
      "[TL]    val acc: 0.657778\n",
      "[TL] Epoch 210 of 500 took 2.378335s\n",
      "[TL]    val loss: 6.151147\n",
      "[TL]    val acc: 0.512222\n",
      "[TL] Epoch 215 of 500 took 2.252725s\n",
      "[TL]    val loss: 4.722528\n",
      "[TL]    val acc: 0.666667\n",
      "[TL] Epoch 220 of 500 took 2.314683s\n",
      "[TL]    val loss: 4.457073\n",
      "[TL]    val acc: 0.589259\n",
      "[TL] Epoch 225 of 500 took 2.327665s\n",
      "[TL]    val loss: 4.123343\n",
      "[TL]    val acc: 0.688148\n",
      "[TL] Epoch 230 of 500 took 2.299490s\n",
      "[TL]    val loss: 4.194646\n",
      "[TL]    val acc: 0.685926\n",
      "[TL] Epoch 235 of 500 took 2.278561s\n",
      "[TL]    val loss: 4.043158\n",
      "[TL]    val acc: 0.705556\n",
      "[TL] Epoch 240 of 500 took 2.318640s\n",
      "[TL]    val loss: 4.970840\n",
      "[TL]    val acc: 0.559259\n",
      "[TL] Epoch 245 of 500 took 2.279964s\n",
      "[TL]    val loss: 4.150265\n",
      "[TL]    val acc: 0.727778\n",
      "[TL] Epoch 250 of 500 took 2.304796s\n",
      "[TL]    val loss: 4.400476\n",
      "[TL]    val acc: 0.715926\n",
      "[TL] Epoch 255 of 500 took 2.264923s\n",
      "[TL]    val loss: 4.991504\n",
      "[TL]    val acc: 0.512963\n",
      "[TL] Epoch 260 of 500 took 2.306335s\n",
      "[TL]    val loss: 3.929696\n",
      "[TL]    val acc: 0.593333\n",
      "[TL] Epoch 265 of 500 took 2.351657s\n",
      "[TL]    val loss: 3.494094\n",
      "[TL]    val acc: 0.719259\n",
      "[TL] Epoch 270 of 500 took 2.304491s\n",
      "[TL]    val loss: 4.007300\n",
      "[TL]    val acc: 0.571852\n",
      "[TL] Epoch 275 of 500 took 2.290893s\n",
      "[TL]    val loss: 3.117243\n",
      "[TL]    val acc: 0.737407\n",
      "[TL] Epoch 280 of 500 took 2.351584s\n",
      "[TL]    val loss: 6.123410\n",
      "[TL]    val acc: 0.514074\n",
      "[TL] Epoch 285 of 500 took 2.320351s\n",
      "[TL]    val loss: 3.716778\n",
      "[TL]    val acc: 0.574074\n",
      "[TL] Epoch 290 of 500 took 2.320472s\n",
      "[TL]    val loss: 2.971687\n",
      "[TL]    val acc: 0.733704\n",
      "[TL] Epoch 295 of 500 took 2.322650s\n",
      "[TL]    val loss: 3.526283\n",
      "[TL]    val acc: 0.627037\n",
      "[TL] Epoch 300 of 500 took 2.253232s\n",
      "[TL]    val loss: 4.308243\n",
      "[TL]    val acc: 0.530741\n",
      "[TL] Epoch 305 of 500 took 2.361847s\n",
      "[TL]    val loss: 2.973368\n",
      "[TL]    val acc: 0.715556\n",
      "[TL] Epoch 310 of 500 took 2.296643s\n",
      "[TL]    val loss: 3.749647\n",
      "[TL]    val acc: 0.664815\n",
      "[TL] Epoch 315 of 500 took 2.271607s\n",
      "[TL]    val loss: 2.893431\n",
      "[TL]    val acc: 0.530000\n",
      "[TL] Epoch 320 of 500 took 2.305232s\n",
      "[TL]    val loss: 2.861025\n",
      "[TL]    val acc: 0.732963\n",
      "[TL] Epoch 325 of 500 took 2.343039s\n",
      "[TL]    val loss: 2.850175\n",
      "[TL]    val acc: 0.662593\n",
      "[TL] Epoch 330 of 500 took 2.259143s\n",
      "[TL]    val loss: 2.412729\n",
      "[TL]    val acc: 0.718519\n",
      "[TL] Epoch 335 of 500 took 2.358791s\n",
      "[TL]    val loss: 2.937977\n",
      "[TL]    val acc: 0.619630\n",
      "[TL] Epoch 340 of 500 took 2.366751s\n",
      "[TL]    val loss: 3.120554\n",
      "[TL]    val acc: 0.714815\n",
      "[TL] Epoch 345 of 500 took 2.259391s\n",
      "[TL]    val loss: 2.732778\n",
      "[TL]    val acc: 0.716296\n",
      "[TL] Epoch 350 of 500 took 2.374368s\n",
      "[TL]    val loss: 2.720778\n",
      "[TL]    val acc: 0.685926\n",
      "[TL] Epoch 355 of 500 took 2.301877s\n",
      "[TL]    val loss: 2.969709\n",
      "[TL]    val acc: 0.473704\n",
      "[TL] Epoch 360 of 500 took 2.345411s\n",
      "[TL]    val loss: 2.826889\n",
      "[TL]    val acc: 0.681852\n",
      "[TL] Epoch 365 of 500 took 2.314714s\n",
      "[TL]    val loss: 2.807899\n",
      "[TL]    val acc: 0.735926\n",
      "[TL] Epoch 370 of 500 took 2.286573s\n",
      "[TL]    val loss: 2.727995\n",
      "[TL]    val acc: 0.643704\n",
      "[TL] Epoch 375 of 500 took 2.366539s\n",
      "[TL]    val loss: 2.686725\n",
      "[TL]    val acc: 0.724815\n",
      "[TL] Epoch 380 of 500 took 2.288193s\n",
      "[TL]    val loss: 2.318127\n",
      "[TL]    val acc: 0.638148\n",
      "[TL] Epoch 385 of 500 took 2.321772s\n",
      "[TL]    val loss: 3.030517\n",
      "[TL]    val acc: 0.662593\n",
      "[TL] Epoch 390 of 500 took 2.295128s\n",
      "[TL]    val loss: 2.305934\n",
      "[TL]    val acc: 0.711111\n",
      "[TL] Epoch 395 of 500 took 2.311561s\n",
      "[TL]    val loss: 2.206148\n",
      "[TL]    val acc: 0.724444\n",
      "[TL] Epoch 400 of 500 took 2.253102s\n",
      "[TL]    val loss: 1.900727\n",
      "[TL]    val acc: 0.718148\n",
      "[TL] Epoch 405 of 500 took 2.291616s\n",
      "[TL]    val loss: 1.989535\n",
      "[TL]    val acc: 0.704444\n",
      "[TL] Epoch 410 of 500 took 2.316953s\n",
      "[TL]    val loss: 2.342151\n",
      "[TL]    val acc: 0.708148\n",
      "[TL] Epoch 415 of 500 took 2.345539s\n",
      "[TL]    val loss: 2.600100\n",
      "[TL]    val acc: 0.654444\n",
      "[TL] Epoch 420 of 500 took 2.340265s\n",
      "[TL]    val loss: 2.499261\n",
      "[TL]    val acc: 0.537778\n",
      "[TL] Epoch 425 of 500 took 2.367581s\n",
      "[TL]    val loss: 1.931909\n",
      "[TL]    val acc: 0.709259\n",
      "[TL] Epoch 430 of 500 took 2.314510s\n",
      "[TL]    val loss: 2.098265\n",
      "[TL]    val acc: 0.745926\n",
      "[TL] Epoch 435 of 500 took 2.327685s\n",
      "[TL]    val loss: 1.694467\n",
      "[TL]    val acc: 0.728889\n",
      "[TL] Epoch 440 of 500 took 2.280844s\n",
      "[TL]    val loss: 1.712408\n",
      "[TL]    val acc: 0.751111\n",
      "[TL] Epoch 445 of 500 took 2.276233s\n",
      "[TL]    val loss: 1.962893\n",
      "[TL]    val acc: 0.748889\n",
      "[TL] Epoch 450 of 500 took 2.313566s\n",
      "[TL]    val loss: 1.654833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]    val acc: 0.717037\n",
      "[TL] Epoch 455 of 500 took 2.283900s\n",
      "[TL]    val loss: 1.756997\n",
      "[TL]    val acc: 0.725185\n",
      "[TL] Epoch 460 of 500 took 2.327770s\n",
      "[TL]    val loss: 1.609701\n",
      "[TL]    val acc: 0.742963\n",
      "[TL] Epoch 465 of 500 took 2.313288s\n",
      "[TL]    val loss: 2.685584\n",
      "[TL]    val acc: 0.575556\n",
      "[TL] Epoch 470 of 500 took 2.257724s\n",
      "[TL]    val loss: 2.393431\n",
      "[TL]    val acc: 0.542222\n",
      "[TL] Epoch 475 of 500 took 2.359835s\n",
      "[TL]    val loss: 1.988273\n",
      "[TL]    val acc: 0.597407\n",
      "[TL] Epoch 480 of 500 took 2.312369s\n",
      "[TL]    val loss: 1.623719\n",
      "[TL]    val acc: 0.738148\n",
      "[TL] Epoch 485 of 500 took 2.342125s\n",
      "[TL]    val loss: 1.629531\n",
      "[TL]    val acc: 0.730370\n",
      "[TL] Epoch 490 of 500 took 2.269831s\n",
      "[TL]    val loss: 1.635894\n",
      "[TL]    val acc: 0.728148\n",
      "[TL] Epoch 495 of 500 took 2.311413s\n",
      "[TL]    val loss: 1.456880\n",
      "[TL]    val acc: 0.753333\n",
      "[TL] Epoch 500 of 500 took 2.307283s\n",
      "[TL]    val loss: 1.671681\n",
      "[TL]    val acc: 0.731481\n",
      "[TL] Total training time: 1178.775795s\n"
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=100, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False, tensorboard=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n",
      "[TL]    test loss: 0.898036\n",
      "[TL]    test acc: 0.756070\n"
     ]
    }
   ],
   "source": [
    "tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x1c5f2963ef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = rgb2mono(i)\n",
    "            remoteImage = i.reshape((1,4800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(25) + \",\" + str((direction[0] - 3) * 15)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
