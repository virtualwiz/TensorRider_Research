{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mono(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    # mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.zeros(4800)\n",
    "    y = np.zeros(1)\n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "\n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = rgb2mono(image)\n",
    "        image = image.reshape((4800))\n",
    "\n",
    "        X = np.vstack((X,image))\n",
    "        y = np.append(y,label)\n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "\n",
    "    y = y.reshape((recordCounter + 1,))\n",
    "    y = y / 40\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")\n",
    "testIterator = tf.python_io.tf_record_iterator(path=\"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n",
      "100->"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->8100->8200->8300->8400->8500->8600->8700->8800->8900->9000->9100->9200->9300->9400->9500->9600->9700->9800->9900->10000->10100->10200->10300->10400->10500->10600->10700->10800->10900->11000->11100->11200->11300->11400->11500->11600->11700->11800->11900->12000->12100->12200->12300->12400->12500->12600->12700->12800->12900->13000->13100->13200->13300->13400->13500->\n",
      "Val...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->\n",
      "Test...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)\n",
    "print(\"\\nTest...\")\n",
    "X_test, y_test = prepareDataArrays(testIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays_reg.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val, xt = X_test, yt = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays_reg.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]\n",
    "X_test = npRecall[\"xt\"]\n",
    "y_test = npRecall[\"yt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.   ,  0.   , ...,  0.   , -0.125, -0.15 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.200e+01, 3.500e+01, 4.460e+02, 1.443e+03, 1.401e+03, 1.498e+03,\n",
       "        5.870e+02, 1.020e+02, 3.808e+03, 2.760e+02, 6.460e+02, 1.158e+03,\n",
       "        1.355e+03, 6.200e+02, 1.790e+02, 2.100e+01, 5.000e+00, 2.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([-0.7    , -0.61625, -0.5325 , -0.44875, -0.365  , -0.28125,\n",
       "        -0.1975 , -0.11375, -0.03   ,  0.05375,  0.1375 ,  0.22125,\n",
       "         0.305  ,  0.38875,  0.4725 ,  0.55625,  0.64   ,  0.72375,\n",
       "         0.8075 ,  0.89125,  0.975  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, 20)\n",
    "# plt.hist(y_val, 20)\n",
    "# plt.hist(y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 4800], name='x')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 4800)\n",
      "[TL] DropoutLayer drop1: keep:0.800000 is_fix:False\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DenseLayer  relu2: 1024 relu\n",
      "[TL] DenseLayer  relu5: 512 relu\n",
      "[TL] DenseLayer  relu6: 256 relu\n",
      "[TL] DenseLayer  output: 1 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu2')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "# network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu3')\n",
    "# network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu4')\n",
    "network = tl.layers.DenseLayer(network, 512, tf.nn.relu, name='relu5')\n",
    "network = tl.layers.DenseLayer(network, 256, tf.nn.relu, name='relu6')\n",
    "network = tl.layers.DenseLayer(network, n_units=1, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.mean_squared_error(tf.argmax(y, 1), y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (4800, 2048)       float32_ref (mean: 1.4310237020254135e-05, median: -5.945898010395467e-06, std: 0.08795341849327087)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (2048, 1024)       float32_ref (mean: 1.4902308066666592e-05, median: 4.604891364579089e-05, std: 0.08796718716621399)   \n",
      "[TL]   param   3: relu2/b:0            (1024,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: relu5/W:0            (1024, 512)        float32_ref (mean: -7.194335921667516e-05, median: 2.5876426661852747e-05, std: 0.08799204975366592)   \n",
      "[TL]   param   5: relu5/b:0            (512,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   6: relu6/W:0            (512, 256)         float32_ref (mean: 0.0001357120054308325, median: 0.00010826616198755801, std: 0.08788598328828812)   \n",
      "[TL]   param   7: relu6/b:0            (256,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   8: output/W:0           (256, 7)           float32_ref (mean: 0.0011578815756365657, median: 0.0019492809660732746, std: 0.0905870795249939)   \n",
      "[TL]   param   9: output/b:0           (7,)               float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 12588551\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: drop1/mul:0          (?, 4800)          float32\n",
      "[TL]   layer   1: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   2: relu2/Relu:0         (?, 1024)          float32\n",
      "[TL]   layer   3: relu5/Relu:0         (?, 512)           float32\n",
      "[TL]   layer   4: relu6/Relu:0         (?, 256)           float32\n",
      "[TL]   layer   5: output/Identity:0    (?, 7)             float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)  \n",
    "cost_summ = tf.summary.scalar('cost', cost)  \n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 2.957723s\n",
      "[TL]    val loss: 306.127439\n",
      "[TL]    val acc: 0.732963\n",
      "[TL] Epoch 5 of 500 took 2.477292s\n",
      "[TL]    val loss: 142.620600\n",
      "[TL]    val acc: 0.646667\n",
      "[TL] Epoch 10 of 500 took 2.271978s\n",
      "[TL]    val loss: 61.790393\n",
      "[TL]    val acc: 0.693333\n",
      "[TL] Epoch 15 of 500 took 2.291489s\n",
      "[TL]    val loss: 59.932724\n",
      "[TL]    val acc: 0.602593\n",
      "[TL] Epoch 20 of 500 took 2.316059s\n",
      "[TL]    val loss: 51.320483\n",
      "[TL]    val acc: 0.494074\n",
      "[TL] Epoch 25 of 500 took 2.384625s\n",
      "[TL]    val loss: 26.097169\n",
      "[TL]    val acc: 0.547037\n",
      "[TL] Epoch 30 of 500 took 2.393724s\n",
      "[TL]    val loss: 20.529029\n",
      "[TL]    val acc: 0.641111\n",
      "[TL] Epoch 35 of 500 took 2.382494s\n",
      "[TL]    val loss: 18.827669\n",
      "[TL]    val acc: 0.736667\n",
      "[TL] Epoch 40 of 500 took 2.454937s\n",
      "[TL]    val loss: 18.191836\n",
      "[TL]    val acc: 0.685185\n",
      "[TL] Epoch 45 of 500 took 2.546659s\n",
      "[TL]    val loss: 23.557425\n",
      "[TL]    val acc: 0.483333\n",
      "[TL] Epoch 50 of 500 took 2.470768s\n",
      "[TL]    val loss: 15.023940\n",
      "[TL]    val acc: 0.708889\n",
      "[TL] Epoch 55 of 500 took 2.491979s\n",
      "[TL]    val loss: 12.350318\n",
      "[TL]    val acc: 0.648148\n",
      "[TL] Epoch 60 of 500 took 2.590190s\n",
      "[TL]    val loss: 13.557469\n",
      "[TL]    val acc: 0.734815\n",
      "[TL] Epoch 65 of 500 took 2.545104s\n",
      "[TL]    val loss: 11.054990\n",
      "[TL]    val acc: 0.702222\n",
      "[TL] Epoch 70 of 500 took 2.525294s\n",
      "[TL]    val loss: 10.775650\n",
      "[TL]    val acc: 0.662593\n",
      "[TL] Epoch 75 of 500 took 2.280570s\n",
      "[TL]    val loss: 9.504146\n",
      "[TL]    val acc: 0.705556\n",
      "[TL] Epoch 80 of 500 took 2.299398s\n",
      "[TL]    val loss: 11.725228\n",
      "[TL]    val acc: 0.410000\n",
      "[TL] Epoch 85 of 500 took 2.373136s\n",
      "[TL]    val loss: 8.979321\n",
      "[TL]    val acc: 0.578519\n",
      "[TL] Epoch 90 of 500 took 2.272153s\n",
      "[TL]    val loss: 7.173568\n",
      "[TL]    val acc: 0.663704\n",
      "[TL] Epoch 95 of 500 took 2.265835s\n",
      "[TL]    val loss: 7.552198\n",
      "[TL]    val acc: 0.661481\n",
      "[TL] Epoch 100 of 500 took 2.297908s\n",
      "[TL]    val loss: 6.691926\n",
      "[TL]    val acc: 0.640000\n",
      "[TL] Epoch 105 of 500 took 2.337026s\n",
      "[TL]    val loss: 6.353435\n",
      "[TL]    val acc: 0.558148\n",
      "[TL] Epoch 110 of 500 took 2.342934s\n",
      "[TL]    val loss: 7.025863\n",
      "[TL]    val acc: 0.534074\n",
      "[TL] Epoch 115 of 500 took 2.335315s\n",
      "[TL]    val loss: 6.919602\n",
      "[TL]    val acc: 0.658519\n",
      "[TL] Epoch 120 of 500 took 2.293727s\n",
      "[TL]    val loss: 4.428245\n",
      "[TL]    val acc: 0.723333\n",
      "[TL] Epoch 125 of 500 took 2.300329s\n",
      "[TL]    val loss: 5.119756\n",
      "[TL]    val acc: 0.645185\n",
      "[TL] Epoch 130 of 500 took 2.332670s\n",
      "[TL]    val loss: 4.454375\n",
      "[TL]    val acc: 0.661481\n",
      "[TL] Epoch 135 of 500 took 2.321836s\n",
      "[TL]    val loss: 4.200758\n",
      "[TL]    val acc: 0.724444\n",
      "[TL] Epoch 140 of 500 took 2.319876s\n",
      "[TL]    val loss: 3.585669\n",
      "[TL]    val acc: 0.689630\n",
      "[TL] Epoch 145 of 500 took 2.281395s\n",
      "[TL]    val loss: 3.709927\n",
      "[TL]    val acc: 0.590370\n",
      "[TL] Epoch 150 of 500 took 2.319924s\n",
      "[TL]    val loss: 3.510088\n",
      "[TL]    val acc: 0.727037\n",
      "[TL] Epoch 155 of 500 took 2.341483s\n",
      "[TL]    val loss: 3.518273\n",
      "[TL]    val acc: 0.648519\n",
      "[TL] Epoch 160 of 500 took 2.359124s\n",
      "[TL]    val loss: 2.993602\n",
      "[TL]    val acc: 0.718889\n",
      "[TL] Epoch 165 of 500 took 2.295358s\n",
      "[TL]    val loss: 2.847054\n",
      "[TL]    val acc: 0.671852\n",
      "[TL] Epoch 170 of 500 took 2.284070s\n",
      "[TL]    val loss: 3.032183\n",
      "[TL]    val acc: 0.708148\n",
      "[TL] Epoch 175 of 500 took 2.404326s\n",
      "[TL]    val loss: 3.050954\n",
      "[TL]    val acc: 0.728148\n",
      "[TL] Epoch 180 of 500 took 2.447663s\n",
      "[TL]    val loss: 2.452860\n",
      "[TL]    val acc: 0.707037\n",
      "[TL] Epoch 185 of 500 took 2.316782s\n",
      "[TL]    val loss: 2.498080\n",
      "[TL]    val acc: 0.637778\n",
      "[TL] Epoch 190 of 500 took 2.373320s\n",
      "[TL]    val loss: 2.334300\n",
      "[TL]    val acc: 0.744074\n",
      "[TL] Epoch 195 of 500 took 2.511676s\n",
      "[TL]    val loss: 2.165211\n",
      "[TL]    val acc: 0.731852\n",
      "[TL] Epoch 200 of 500 took 2.318194s\n",
      "[TL]    val loss: 2.737265\n",
      "[TL]    val acc: 0.728889\n",
      "[TL] Epoch 205 of 500 took 2.345233s\n",
      "[TL]    val loss: 2.281722\n",
      "[TL]    val acc: 0.732593\n",
      "[TL] Epoch 210 of 500 took 2.640809s\n",
      "[TL]    val loss: 1.939848\n",
      "[TL]    val acc: 0.708889\n",
      "[TL] Epoch 215 of 500 took 2.291843s\n",
      "[TL]    val loss: 1.949657\n",
      "[TL]    val acc: 0.727407\n",
      "[TL] Epoch 220 of 500 took 2.354253s\n",
      "[TL]    val loss: 1.994710\n",
      "[TL]    val acc: 0.649259\n",
      "[TL] Epoch 225 of 500 took 2.316735s\n",
      "[TL]    val loss: 1.842951\n",
      "[TL]    val acc: 0.637037\n",
      "[TL] Epoch 230 of 500 took 2.347029s\n",
      "[TL]    val loss: 1.858289\n",
      "[TL]    val acc: 0.737037\n",
      "[TL] Epoch 235 of 500 took 2.299466s\n",
      "[TL]    val loss: 1.804024\n",
      "[TL]    val acc: 0.742963\n",
      "[TL] Epoch 240 of 500 took 2.287714s\n",
      "[TL]    val loss: 1.706531\n",
      "[TL]    val acc: 0.697778\n",
      "[TL] Epoch 245 of 500 took 2.236480s\n",
      "[TL]    val loss: 1.518147\n",
      "[TL]    val acc: 0.736296\n",
      "[TL] Epoch 250 of 500 took 2.283339s\n",
      "[TL]    val loss: 1.496938\n",
      "[TL]    val acc: 0.738889\n",
      "[TL] Epoch 255 of 500 took 2.328698s\n",
      "[TL]    val loss: 1.520348\n",
      "[TL]    val acc: 0.721852\n",
      "[TL] Epoch 260 of 500 took 2.391339s\n",
      "[TL]    val loss: 1.575660\n",
      "[TL]    val acc: 0.692222\n",
      "[TL] Epoch 265 of 500 took 2.284058s\n",
      "[TL]    val loss: 1.371913\n",
      "[TL]    val acc: 0.732222\n",
      "[TL] Epoch 270 of 500 took 2.328546s\n",
      "[TL]    val loss: 1.426741\n",
      "[TL]    val acc: 0.732593\n",
      "[TL] Epoch 275 of 500 took 2.284835s\n",
      "[TL]    val loss: 1.483036\n",
      "[TL]    val acc: 0.731481\n",
      "[TL] Epoch 280 of 500 took 2.304147s\n",
      "[TL]    val loss: 1.369864\n",
      "[TL]    val acc: 0.739259\n",
      "[TL] Epoch 285 of 500 took 2.362307s\n",
      "[TL]    val loss: 1.485139\n",
      "[TL]    val acc: 0.666296\n",
      "[TL] Epoch 290 of 500 took 2.304128s\n",
      "[TL]    val loss: 1.307386\n",
      "[TL]    val acc: 0.723704\n",
      "[TL] Epoch 295 of 500 took 2.379106s\n",
      "[TL]    val loss: 1.215829\n",
      "[TL]    val acc: 0.735185\n",
      "[TL] Epoch 300 of 500 took 2.389080s\n",
      "[TL]    val loss: 1.218372\n",
      "[TL]    val acc: 0.730000\n",
      "[TL] Epoch 305 of 500 took 2.337421s\n",
      "[TL]    val loss: 1.349372\n",
      "[TL]    val acc: 0.729259\n",
      "[TL] Epoch 310 of 500 took 2.401951s\n",
      "[TL]    val loss: 1.254845\n",
      "[TL]    val acc: 0.704444\n",
      "[TL] Epoch 315 of 500 took 2.300258s\n",
      "[TL]    val loss: 1.183860\n",
      "[TL]    val acc: 0.734815\n",
      "[TL] Epoch 320 of 500 took 2.448018s\n",
      "[TL]    val loss: 1.197624\n",
      "[TL]    val acc: 0.734815\n",
      "[TL] Epoch 325 of 500 took 2.273530s\n",
      "[TL]    val loss: 1.148205\n",
      "[TL]    val acc: 0.736296\n",
      "[TL] Epoch 330 of 500 took 2.287646s\n",
      "[TL]    val loss: 1.156025\n",
      "[TL]    val acc: 0.742222\n",
      "[TL] Epoch 335 of 500 took 2.301818s\n",
      "[TL]    val loss: 1.208360\n",
      "[TL]    val acc: 0.688889\n",
      "[TL] Epoch 340 of 500 took 2.327718s\n",
      "[TL]    val loss: 1.091684\n",
      "[TL]    val acc: 0.723333\n",
      "[TL] Epoch 345 of 500 took 2.262841s\n",
      "[TL]    val loss: 1.069265\n",
      "[TL]    val acc: 0.742593\n",
      "[TL] Epoch 350 of 500 took 2.301761s\n",
      "[TL]    val loss: 1.060051\n",
      "[TL]    val acc: 0.719630\n",
      "[TL] Epoch 355 of 500 took 2.458168s\n",
      "[TL]    val loss: 1.178867\n",
      "[TL]    val acc: 0.705185\n",
      "[TL] Epoch 360 of 500 took 2.309076s\n",
      "[TL]    val loss: 1.014980\n",
      "[TL]    val acc: 0.738519\n",
      "[TL] Epoch 365 of 500 took 2.265853s\n",
      "[TL]    val loss: 1.014025\n",
      "[TL]    val acc: 0.744815\n",
      "[TL] Epoch 370 of 500 took 2.315919s\n",
      "[TL]    val loss: 1.037913\n",
      "[TL]    val acc: 0.731481\n",
      "[TL] Epoch 375 of 500 took 2.496638s\n",
      "[TL]    val loss: 1.040258\n",
      "[TL]    val acc: 0.725926\n",
      "[TL] Epoch 380 of 500 took 2.325599s\n",
      "[TL]    val loss: 1.020340\n",
      "[TL]    val acc: 0.735185\n",
      "[TL] Epoch 385 of 500 took 2.264090s\n",
      "[TL]    val loss: 0.958009\n",
      "[TL]    val acc: 0.739630\n",
      "[TL] Epoch 390 of 500 took 2.331009s\n",
      "[TL]    val loss: 0.971548\n",
      "[TL]    val acc: 0.730741\n",
      "[TL] Epoch 395 of 500 took 2.350197s\n",
      "[TL]    val loss: 0.954871\n",
      "[TL]    val acc: 0.721481\n",
      "[TL] Epoch 400 of 500 took 2.339028s\n",
      "[TL]    val loss: 0.976210\n",
      "[TL]    val acc: 0.738148\n",
      "[TL] Epoch 405 of 500 took 2.295823s\n",
      "[TL]    val loss: 0.979766\n",
      "[TL]    val acc: 0.737037\n",
      "[TL] Epoch 410 of 500 took 2.273542s\n",
      "[TL]    val loss: 0.930885\n",
      "[TL]    val acc: 0.741111\n",
      "[TL] Epoch 415 of 500 took 2.334964s\n",
      "[TL]    val loss: 0.939000\n",
      "[TL]    val acc: 0.733704\n",
      "[TL] Epoch 420 of 500 took 2.302270s\n",
      "[TL]    val loss: 1.028462\n",
      "[TL]    val acc: 0.700370\n",
      "[TL] Epoch 425 of 500 took 2.308527s\n",
      "[TL]    val loss: 0.958467\n",
      "[TL]    val acc: 0.718519\n",
      "[TL] Epoch 430 of 500 took 2.319240s\n",
      "[TL]    val loss: 0.904361\n",
      "[TL]    val acc: 0.744815\n",
      "[TL] Epoch 435 of 500 took 2.312685s\n",
      "[TL]    val loss: 0.893492\n",
      "[TL]    val acc: 0.739259\n",
      "[TL] Epoch 440 of 500 took 2.278244s\n",
      "[TL]    val loss: 0.973518\n",
      "[TL]    val acc: 0.728148\n",
      "[TL] Epoch 445 of 500 took 2.294878s\n",
      "[TL]    val loss: 0.930538\n",
      "[TL]    val acc: 0.734444\n",
      "[TL] Epoch 450 of 500 took 2.303660s\n",
      "[TL]    val loss: 0.902190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]    val acc: 0.730370\n",
      "[TL] Epoch 455 of 500 took 2.265413s\n",
      "[TL]    val loss: 0.962322\n",
      "[TL]    val acc: 0.740741\n",
      "[TL] Epoch 460 of 500 took 2.298908s\n",
      "[TL]    val loss: 0.885788\n",
      "[TL]    val acc: 0.727407\n",
      "[TL] Epoch 465 of 500 took 2.283476s\n",
      "[TL]    val loss: 0.915414\n",
      "[TL]    val acc: 0.729259\n",
      "[TL] Epoch 470 of 500 took 2.291841s\n",
      "[TL]    val loss: 0.926052\n",
      "[TL]    val acc: 0.716667\n",
      "[TL] Epoch 475 of 500 took 2.307572s\n",
      "[TL]    val loss: 0.895707\n",
      "[TL]    val acc: 0.741111\n",
      "[TL] Epoch 480 of 500 took 2.327882s\n",
      "[TL]    val loss: 0.899451\n",
      "[TL]    val acc: 0.738148\n",
      "[TL] Epoch 485 of 500 took 2.286065s\n",
      "[TL]    val loss: 0.903449\n",
      "[TL]    val acc: 0.741111\n",
      "[TL] Epoch 490 of 500 took 2.358186s\n",
      "[TL]    val loss: 0.893328\n",
      "[TL]    val acc: 0.731111\n",
      "[TL] Epoch 495 of 500 took 2.282546s\n",
      "[TL]    val loss: 0.939815\n",
      "[TL]    val acc: 0.723704\n",
      "[TL] Epoch 500 of 500 took 2.350995s\n",
      "[TL]    val loss: 0.917578\n",
      "[TL]    val acc: 0.744074\n",
      "[TL] Total training time: 1192.171118s\n"
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=100, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False, tensorboard=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n",
      "[TL]    test loss: 0.718053\n",
      "[TL]    test acc: 0.754356\n"
     ]
    }
   ],
   "source": [
    "tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model_reg.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x1e6824b8320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model_reg.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython import display\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = rgb2mono(i)\n",
    "            remoteImage = i.reshape((1,4800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(25) + \",\" + str((direction[0] - 3) * 20)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
