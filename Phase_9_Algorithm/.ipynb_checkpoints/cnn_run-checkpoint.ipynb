{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mono(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    # mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.zeros(4800)\n",
    "    y = np.zeros(1)\n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "\n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = rgb2mono(image)\n",
    "        image = image.reshape((4800))\n",
    "        \n",
    "        X = np.append(X,image)\n",
    "        y = np.append(y,label)\n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "            \n",
    "    X = X.reshape((recordCounter + 1, 60, 80, 1))\n",
    "    y = y.reshape((recordCounter + 1,))\n",
    "    y = np.round(y / 12)\n",
    "    y = y + 3\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")\n",
    "testIterator = tf.python_io.tf_record_iterator(path=\"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f6f7cdb83bee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTrain...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepareDataArrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainIterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nVal...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepareDataArrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalIterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTest...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8597c9a7eac2>\u001b[0m in \u001b[0;36mprepareDataArrays\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecordCounter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)\n",
    "print(\"\\nTest...\")\n",
    "X_test, y_test = prepareDataArrays(testIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays2d.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val, xt = X_test, yt = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays2d.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]\n",
    "X_test = npRecall[\"xt\"]\n",
    "y_test = npRecall[\"yt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.930e+02, 0.000e+00, 4.565e+03, 0.000e+00, 4.786e+03, 0.000e+00,\n",
       "        3.352e+03, 0.000e+00, 3.960e+02, 3.000e+00]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "# plt.hist(y_val)\n",
    "# plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 4800], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 4800)\n",
      "[TL] DenseLayer  relu1: 2048 relu\n",
      "[TL] DenseLayer  relu2: 1024 relu\n",
      "[TL] DenseLayer  relu6: 256 relu\n",
      "[TL] DenseLayer  output: 7 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 2048, tf.nn.relu, name='relu1')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu2')\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "# network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu3')\n",
    "# network = tl.layers.DenseLayer(network, 1024, tf.nn.relu, name='relu4')\n",
    "# network = tl.layers.DenseLayer(network, 512, tf.nn.relu, name='relu5')\n",
    "network = tl.layers.DenseLayer(network, 256, tf.nn.relu, name='relu6')\n",
    "network = tl.layers.DenseLayer(network, n_units=7, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (4800, 2048)       float32_ref (mean: 7.190340511442628e-06, median: 6.96055794833228e-05, std: 0.08794520795345306)   \n",
      "[TL]   param   1: relu1/b:0            (2048,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (2048, 1024)       float32_ref (mean: -2.2341419025906362e-07, median: 1.073072235158179e-05, std: 0.08793698996305466)   \n",
      "[TL]   param   3: relu2/b:0            (1024,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: relu6/W:0            (1024, 256)        float32_ref (mean: 3.808444307651371e-05, median: 0.00013325767940841615, std: 0.08798779547214508)   \n",
      "[TL]   param   5: relu6/b:0            (256,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   6: output/W:0           (256, 7)           float32_ref (mean: -0.007429237011820078, median: -0.005507505498826504, std: 0.08977370709180832)   \n",
      "[TL]   param   7: output/b:0           (7,)               float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 12194823\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: relu1/Relu:0         (?, 2048)          float32\n",
      "[TL]   layer   1: relu2/Relu:0         (?, 1024)          float32\n",
      "[TL]   layer   2: relu6/Relu:0         (?, 256)           float32\n",
      "[TL]   layer   3: output/Identity:0    (?, 7)             float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Setting up TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_summ = tf.summary.scalar('acc', acc)  \n",
    "cost_summ = tf.summary.scalar('cost', cost)  \n",
    "summary = tf.summary.merge_all()  \n",
    "writer = tf.summary.FileWriter('./logs')  \n",
    "writer.add_graph(sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 2.497343s\n",
      "[TL]    val loss: 233.334439\n",
      "[TL]    val acc: 0.520370\n",
      "[TL] Epoch 5 of 500 took 2.236042s\n",
      "[TL]    val loss: 164.100705\n",
      "[TL]    val acc: 0.667037\n",
      "[TL] Epoch 10 of 500 took 2.274102s\n",
      "[TL]    val loss: 152.888161\n",
      "[TL]    val acc: 0.577037\n",
      "[TL] Epoch 15 of 500 took 2.213147s\n",
      "[TL]    val loss: 81.082731\n",
      "[TL]    val acc: 0.666296\n",
      "[TL] Epoch 20 of 500 took 2.194913s\n",
      "[TL]    val loss: 70.443339\n",
      "[TL]    val acc: 0.675556\n",
      "[TL] Epoch 25 of 500 took 2.234990s\n",
      "[TL]    val loss: 73.300531\n",
      "[TL]    val acc: 0.673333\n",
      "[TL] Epoch 30 of 500 took 2.157495s\n",
      "[TL]    val loss: 67.741887\n",
      "[TL]    val acc: 0.560000\n",
      "[TL] Epoch 35 of 500 took 2.258878s\n",
      "[TL]    val loss: 52.348758\n",
      "[TL]    val acc: 0.718889\n",
      "[TL] Epoch 40 of 500 took 2.264009s\n",
      "[TL]    val loss: 83.480363\n",
      "[TL]    val acc: 0.553704\n",
      "[TL] Epoch 45 of 500 took 2.221843s\n",
      "[TL]    val loss: 40.454407\n",
      "[TL]    val acc: 0.677778\n",
      "[TL] Epoch 50 of 500 took 2.260371s\n",
      "[TL]    val loss: 53.719142\n",
      "[TL]    val acc: 0.711852\n",
      "[TL] Epoch 55 of 500 took 2.247272s\n",
      "[TL]    val loss: 41.757502\n",
      "[TL]    val acc: 0.647037\n",
      "[TL] Epoch 60 of 500 took 2.189097s\n",
      "[TL]    val loss: 36.614424\n",
      "[TL]    val acc: 0.618889\n",
      "[TL] Epoch 65 of 500 took 2.211633s\n",
      "[TL]    val loss: 27.814653\n",
      "[TL]    val acc: 0.673704\n",
      "[TL] Epoch 70 of 500 took 2.211704s\n",
      "[TL]    val loss: 28.552876\n",
      "[TL]    val acc: 0.661852\n",
      "[TL] Epoch 75 of 500 took 2.206571s\n",
      "[TL]    val loss: 30.680796\n",
      "[TL]    val acc: 0.584444\n",
      "[TL] Epoch 80 of 500 took 2.186825s\n",
      "[TL]    val loss: 22.934909\n",
      "[TL]    val acc: 0.665185\n",
      "[TL] Epoch 85 of 500 took 2.239802s\n",
      "[TL]    val loss: 18.401539\n",
      "[TL]    val acc: 0.703333\n",
      "[TL] Epoch 90 of 500 took 2.329763s\n",
      "[TL]    val loss: 22.238615\n",
      "[TL]    val acc: 0.565185\n",
      "[TL] Epoch 95 of 500 took 2.169923s\n",
      "[TL]    val loss: 16.755086\n",
      "[TL]    val acc: 0.658519\n",
      "[TL] Epoch 100 of 500 took 2.198960s\n",
      "[TL]    val loss: 17.433541\n",
      "[TL]    val acc: 0.655926\n",
      "[TL] Epoch 105 of 500 took 2.150638s\n",
      "[TL]    val loss: 12.994600\n",
      "[TL]    val acc: 0.672222\n",
      "[TL] Epoch 110 of 500 took 2.134981s\n",
      "[TL]    val loss: 11.947302\n",
      "[TL]    val acc: 0.670741\n",
      "[TL] Epoch 115 of 500 took 2.171533s\n",
      "[TL]    val loss: 21.803377\n",
      "[TL]    val acc: 0.538519\n",
      "[TL] Epoch 120 of 500 took 2.169471s\n",
      "[TL]    val loss: 9.783917\n",
      "[TL]    val acc: 0.663704\n",
      "[TL] Epoch 125 of 500 took 2.164615s\n",
      "[TL]    val loss: 9.887950\n",
      "[TL]    val acc: 0.681481\n",
      "[TL] Epoch 130 of 500 took 2.174442s\n",
      "[TL]    val loss: 8.647851\n",
      "[TL]    val acc: 0.653704\n",
      "[TL] Epoch 135 of 500 took 2.245258s\n",
      "[TL]    val loss: 8.175688\n",
      "[TL]    val acc: 0.670741\n",
      "[TL] Epoch 140 of 500 took 2.265491s\n",
      "[TL]    val loss: 7.423027\n",
      "[TL]    val acc: 0.715185\n",
      "[TL] Epoch 145 of 500 took 2.162110s\n",
      "[TL]    val loss: 7.889886\n",
      "[TL]    val acc: 0.695556\n",
      "[TL] Epoch 150 of 500 took 2.148195s\n",
      "[TL]    val loss: 7.931054\n",
      "[TL]    val acc: 0.655185\n",
      "[TL] Epoch 155 of 500 took 2.157334s\n",
      "[TL]    val loss: 7.354565\n",
      "[TL]    val acc: 0.662963\n",
      "[TL] Epoch 160 of 500 took 2.223476s\n",
      "[TL]    val loss: 5.704566\n",
      "[TL]    val acc: 0.685556\n",
      "[TL] Epoch 165 of 500 took 2.175158s\n",
      "[TL]    val loss: 7.166728\n",
      "[TL]    val acc: 0.600000\n",
      "[TL] Epoch 170 of 500 took 2.249088s\n",
      "[TL]    val loss: 6.533375\n",
      "[TL]    val acc: 0.690000\n",
      "[TL] Epoch 175 of 500 took 2.246468s\n",
      "[TL]    val loss: 6.106627\n",
      "[TL]    val acc: 0.654074\n",
      "[TL] Epoch 180 of 500 took 2.202618s\n",
      "[TL]    val loss: 6.002446\n",
      "[TL]    val acc: 0.702593\n",
      "[TL] Epoch 185 of 500 took 2.181030s\n",
      "[TL]    val loss: 5.959857\n",
      "[TL]    val acc: 0.682963\n",
      "[TL] Epoch 190 of 500 took 2.189028s\n",
      "[TL]    val loss: 4.768470\n",
      "[TL]    val acc: 0.704444\n",
      "[TL] Epoch 195 of 500 took 2.183244s\n",
      "[TL]    val loss: 5.269561\n",
      "[TL]    val acc: 0.672222\n",
      "[TL] Epoch 200 of 500 took 2.189713s\n",
      "[TL]    val loss: 4.446905\n",
      "[TL]    val acc: 0.682222\n",
      "[TL] Epoch 205 of 500 took 2.190754s\n",
      "[TL]    val loss: 5.245370\n",
      "[TL]    val acc: 0.672222\n",
      "[TL] Epoch 210 of 500 took 2.172160s\n",
      "[TL]    val loss: 4.460796\n",
      "[TL]    val acc: 0.690741\n",
      "[TL] Epoch 215 of 500 took 2.159172s\n",
      "[TL]    val loss: 4.552973\n",
      "[TL]    val acc: 0.703333\n",
      "[TL] Epoch 220 of 500 took 2.253523s\n",
      "[TL]    val loss: 3.615872\n",
      "[TL]    val acc: 0.700370\n",
      "[TL] Epoch 225 of 500 took 2.227856s\n",
      "[TL]    val loss: 4.410725\n",
      "[TL]    val acc: 0.643704\n",
      "[TL] Epoch 230 of 500 took 2.151083s\n",
      "[TL]    val loss: 4.694722\n",
      "[TL]    val acc: 0.680741\n",
      "[TL] Epoch 235 of 500 took 2.156434s\n",
      "[TL]    val loss: 3.942745\n",
      "[TL]    val acc: 0.687037\n",
      "[TL] Epoch 240 of 500 took 2.172433s\n",
      "[TL]    val loss: 3.949928\n",
      "[TL]    val acc: 0.698148\n",
      "[TL] Epoch 245 of 500 took 2.172443s\n",
      "[TL]    val loss: 3.973305\n",
      "[TL]    val acc: 0.681111\n",
      "[TL] Epoch 250 of 500 took 2.204170s\n",
      "[TL]    val loss: 5.152747\n",
      "[TL]    val acc: 0.641481\n",
      "[TL] Epoch 255 of 500 took 2.192190s\n",
      "[TL]    val loss: 3.562403\n",
      "[TL]    val acc: 0.700370\n",
      "[TL] Epoch 260 of 500 took 2.174499s\n",
      "[TL]    val loss: 4.011553\n",
      "[TL]    val acc: 0.672963\n",
      "[TL] Epoch 265 of 500 took 2.197054s\n",
      "[TL]    val loss: 3.436286\n",
      "[TL]    val acc: 0.696296\n",
      "[TL] Epoch 270 of 500 took 2.190871s\n",
      "[TL]    val loss: 3.236440\n",
      "[TL]    val acc: 0.665556\n",
      "[TL] Epoch 275 of 500 took 2.299482s\n",
      "[TL]    val loss: 3.858240\n",
      "[TL]    val acc: 0.682593\n",
      "[TL] Epoch 280 of 500 took 2.154182s\n",
      "[TL]    val loss: 3.733243\n",
      "[TL]    val acc: 0.713704\n",
      "[TL] Epoch 285 of 500 took 2.161827s\n",
      "[TL]    val loss: 3.722083\n",
      "[TL]    val acc: 0.654815\n",
      "[TL] Epoch 290 of 500 took 2.165161s\n",
      "[TL]    val loss: 3.790831\n",
      "[TL]    val acc: 0.680370\n",
      "[TL] Epoch 295 of 500 took 2.161782s\n",
      "[TL]    val loss: 3.473523\n",
      "[TL]    val acc: 0.660370\n",
      "[TL] Epoch 300 of 500 took 2.248063s\n",
      "[TL]    val loss: 5.150260\n",
      "[TL]    val acc: 0.615556\n",
      "[TL] Epoch 305 of 500 took 2.304264s\n",
      "[TL]    val loss: 3.361705\n",
      "[TL]    val acc: 0.717037\n",
      "[TL] Epoch 310 of 500 took 2.162906s\n",
      "[TL]    val loss: 3.948555\n",
      "[TL]    val acc: 0.645926\n",
      "[TL] Epoch 315 of 500 took 2.149332s\n",
      "[TL]    val loss: 3.252559\n",
      "[TL]    val acc: 0.708889\n",
      "[TL] Epoch 320 of 500 took 2.150982s\n",
      "[TL]    val loss: 2.998617\n",
      "[TL]    val acc: 0.712222\n",
      "[TL] Epoch 325 of 500 took 2.169163s\n",
      "[TL]    val loss: 3.541733\n",
      "[TL]    val acc: 0.702593\n",
      "[TL] Epoch 330 of 500 took 2.173141s\n",
      "[TL]    val loss: 3.610864\n",
      "[TL]    val acc: 0.674074\n",
      "[TL] Epoch 335 of 500 took 2.216241s\n",
      "[TL]    val loss: 4.160969\n",
      "[TL]    val acc: 0.650000\n",
      "[TL] Epoch 340 of 500 took 2.316406s\n",
      "[TL]    val loss: 3.151343\n",
      "[TL]    val acc: 0.677407\n",
      "[TL] Epoch 345 of 500 took 2.156462s\n",
      "[TL]    val loss: 3.404768\n",
      "[TL]    val acc: 0.692963\n",
      "[TL] Epoch 350 of 500 took 2.257355s\n",
      "[TL]    val loss: 4.357613\n",
      "[TL]    val acc: 0.708148\n",
      "[TL] Epoch 355 of 500 took 2.205227s\n",
      "[TL]    val loss: 3.004162\n",
      "[TL]    val acc: 0.679259\n",
      "[TL] Epoch 360 of 500 took 2.142688s\n",
      "[TL]    val loss: 3.251799\n",
      "[TL]    val acc: 0.717778\n",
      "[TL] Epoch 365 of 500 took 2.181351s\n",
      "[TL]    val loss: 3.331927\n",
      "[TL]    val acc: 0.718148\n",
      "[TL] Epoch 370 of 500 took 2.173697s\n",
      "[TL]    val loss: 3.781594\n",
      "[TL]    val acc: 0.672963\n",
      "[TL] Epoch 375 of 500 took 2.266159s\n",
      "[TL]    val loss: 4.119067\n",
      "[TL]    val acc: 0.652593\n",
      "[TL] Epoch 380 of 500 took 2.224442s\n",
      "[TL]    val loss: 3.433486\n",
      "[TL]    val acc: 0.676296\n",
      "[TL] Epoch 385 of 500 took 2.180114s\n",
      "[TL]    val loss: 3.140800\n",
      "[TL]    val acc: 0.706667\n",
      "[TL] Epoch 390 of 500 took 2.146180s\n",
      "[TL]    val loss: 3.825013\n",
      "[TL]    val acc: 0.666667\n",
      "[TL] Epoch 395 of 500 took 2.182037s\n",
      "[TL]    val loss: 3.382560\n",
      "[TL]    val acc: 0.697407\n",
      "[TL] Epoch 400 of 500 took 2.174308s\n",
      "[TL]    val loss: 3.080238\n",
      "[TL]    val acc: 0.694815\n",
      "[TL] Epoch 405 of 500 took 2.179721s\n",
      "[TL]    val loss: 3.999949\n",
      "[TL]    val acc: 0.659259\n",
      "[TL] Epoch 410 of 500 took 2.225139s\n",
      "[TL]    val loss: 3.484764\n",
      "[TL]    val acc: 0.662963\n",
      "[TL] Epoch 415 of 500 took 2.243362s\n",
      "[TL]    val loss: 3.373438\n",
      "[TL]    val acc: 0.684815\n",
      "[TL] Epoch 420 of 500 took 2.184958s\n",
      "[TL]    val loss: 2.954070\n",
      "[TL]    val acc: 0.710741\n",
      "[TL] Epoch 425 of 500 took 2.383234s\n",
      "[TL]    val loss: 3.160082\n",
      "[TL]    val acc: 0.728148\n",
      "[TL] Epoch 430 of 500 took 2.248418s\n",
      "[TL]    val loss: 3.627173\n",
      "[TL]    val acc: 0.667778\n",
      "[TL] Epoch 435 of 500 took 2.235315s\n",
      "[TL]    val loss: 3.279336\n",
      "[TL]    val acc: 0.687778\n",
      "[TL] Epoch 440 of 500 took 2.253081s\n",
      "[TL]    val loss: 3.799373\n",
      "[TL]    val acc: 0.651852\n",
      "[TL] Epoch 445 of 500 took 2.201683s\n",
      "[TL]    val loss: 3.327480\n",
      "[TL]    val acc: 0.712963\n",
      "[TL] Epoch 450 of 500 took 2.257189s\n",
      "[TL]    val loss: 3.628455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]    val acc: 0.688148\n",
      "[TL] Epoch 455 of 500 took 2.198026s\n",
      "[TL]    val loss: 3.724424\n",
      "[TL]    val acc: 0.693333\n",
      "[TL] Epoch 460 of 500 took 2.151978s\n",
      "[TL]    val loss: 3.718488\n",
      "[TL]    val acc: 0.687407\n",
      "[TL] Epoch 465 of 500 took 2.275834s\n",
      "[TL]    val loss: 3.395018\n",
      "[TL]    val acc: 0.716296\n",
      "[TL] Epoch 470 of 500 took 2.276175s\n",
      "[TL]    val loss: 3.418183\n",
      "[TL]    val acc: 0.715185\n",
      "[TL] Epoch 475 of 500 took 2.276052s\n",
      "[TL]    val loss: 3.309484\n",
      "[TL]    val acc: 0.706667\n",
      "[TL] Epoch 480 of 500 took 2.222734s\n",
      "[TL]    val loss: 3.282557\n",
      "[TL]    val acc: 0.685926\n",
      "[TL] Epoch 485 of 500 took 2.247290s\n",
      "[TL]    val loss: 3.274856\n",
      "[TL]    val acc: 0.712593\n",
      "[TL] Epoch 490 of 500 took 2.233898s\n",
      "[TL]    val loss: 3.719170\n",
      "[TL]    val acc: 0.682963\n",
      "[TL] Epoch 495 of 500 took 2.176344s\n",
      "[TL]    val loss: 3.516879\n",
      "[TL]    val acc: 0.709630\n",
      "[TL] Epoch 500 of 500 took 2.302044s\n",
      "[TL]    val loss: 3.542517\n",
      "[TL]    val acc: 0.706296\n",
      "[TL] Total training time: 1125.185577s\n"
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=100, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False, tensorboard=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n",
      "[TL]    test loss: 3.267696\n",
      "[TL]    test acc: 0.694659\n"
     ]
    }
   ],
   "source": [
    "tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model2d.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x270a7b145c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model2d.npz', network=network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython import display\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = rgb2mono(i)\n",
    "            remoteImage = i.reshape((1,4800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, network, remoteImage, x, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(25) + \",\" + str((direction[0] - 3) * 15)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
