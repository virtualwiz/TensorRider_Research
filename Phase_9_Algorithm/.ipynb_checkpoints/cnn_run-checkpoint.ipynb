{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRider Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "from tensorlayer.layers import *\n",
    "LayersConfig.tf_dtype = tf.float16  # tf.float32  tf.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mono(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    # mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.zeros(4800)\n",
    "    y = np.zeros(1)\n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "\n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((60, 80, 3))\n",
    "        image = rgb2mono(image)\n",
    "        image = image.reshape((4800))\n",
    "        \n",
    "        X = np.append(X,image)\n",
    "        y = np.append(y,label)\n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter,end = '->')\n",
    "            \n",
    "    X = X.reshape((recordCounter + 1, 60, 80, 1))\n",
    "    y = y.reshape((recordCounter + 1,))\n",
    "    y = np.round(y / 12)\n",
    "    y = y + 3\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")\n",
    "testIterator = tf.python_io.tf_record_iterator(path=\"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train...\n",
      "100->"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->3600->3700->3800->3900->4000->4100->4200->4300->4400->4500->4600->4700->4800->4900->5000->5100->5200->5300->5400->5500->5600->5700->5800->5900->6000->6100->6200->6300->6400->6500->6600->6700->6800->6900->7000->7100->7200->7300->7400->7500->7600->7700->7800->7900->8000->8100->8200->8300->8400->8500->8600->8700->8800->8900->9000->9100->9200->9300->9400->9500->9600->9700->9800->9900->10000->10100->10200->10300->10400->10500->10600->10700->10800->10900->11000->11100->11200->11300->11400->11500->11600->11700->11800->11900->12000->12100->12200->12300->12400->12500->12600->12700->12800->12900->13000->13100->13200->13300->13400->13500->\n",
      "Val...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->\n",
      "Test...\n",
      "100->200->300->400->500->600->700->800->900->1000->1100->1200->1300->1400->1500->1600->1700->1800->1900->2000->2100->2200->2300->2400->2500->2600->2700->2800->2900->3000->3100->3200->3300->3400->3500->"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"\\nVal...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)\n",
    "print(\"\\nTest...\")\n",
    "X_test, y_test = prepareDataArrays(testIterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays -> NPZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"arrays2d.npz\", xtr = X_train, ytr = y_train, xval = X_val, yval = y_val, xt = X_test, yt = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPZ File -> Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRecall = np.load(\"arrays2d.npz\")\n",
    "X_train = npRecall[\"xtr\"]\n",
    "y_train = npRecall[\"ytr\"]\n",
    "X_val = npRecall[\"xval\"]\n",
    "y_val = npRecall[\"yval\"]\n",
    "X_test = npRecall[\"xt\"]\n",
    "y_test = npRecall[\"yt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.930e+02, 0.000e+00, 4.565e+03, 0.000e+00, 4.786e+03, 0.000e+00,\n",
       "        3.352e+03, 0.000e+00, 3.960e+02, 3.000e+00]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "# plt.hist(y_val)\n",
    "# plt.hist(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "x = tf.placeholder(LayersConfig.tf_dtype, shape=[batch_size, 60, 80, 1])\n",
    "y_ = tf.placeholder(tf.int64, shape=[batch_size])\n",
    "\n",
    "rx = tf.placeholder(LayersConfig.tf_dtype, shape=[1, 60, 80, 1])\n",
    "ry_ = tf.placeholder(tf.int64, shape=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        n = InputLayer(x, name='input')\n",
    "        # cnn\n",
    "        n = Conv2d(n, 32, (5, 5), (1, 1), padding='SAME', name='cnn1')\n",
    "        n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, name='bn1')\n",
    "        n = MaxPool2d(n, (2, 2), (2, 2), padding='SAME', name='pool1')\n",
    "        n = Conv2d(n, 64, (5, 5), (1, 1), padding='SAME', name='cnn2')\n",
    "        n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, name='bn2')\n",
    "        n = MaxPool2d(n, (2, 2), (2, 2), padding='SAME', name='pool2')\n",
    "        # mlp\n",
    "        n = FlattenLayer(n, name='flatten')\n",
    "        n = DropoutLayer(n, 0.5, True, is_train, name='drop1')\n",
    "        n = DenseLayer(n, 256, act=tf.nn.relu, name='relu1')\n",
    "        n = DropoutLayer(n, 0.5, True, is_train, name='drop2')\n",
    "        n = DenseLayer(n, 7, act=tf.identity, name='output')\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  model/input: (128, 60, 80, 1)\n",
      "[TL] Conv2dLayer model/cnn1: shape:(5, 5, 1, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer model/bn1: decay:0.900000 epsilon:0.000010 act:relu is_train:True\n",
      "[TL] PoolLayer   model/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer model/cnn2: shape:(5, 5, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer model/bn2: decay:0.900000 epsilon:0.000010 act:relu is_train:True\n",
      "[TL] PoolLayer   model/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] FlattenLayer model/flatten: 19200\n",
      "[TL] DropoutLayer model/drop1: keep:0.500000 is_fix:True\n",
      "[TL] DenseLayer  model/relu1: 256 relu\n",
      "[TL] DropoutLayer model/drop2: keep:0.500000 is_fix:True\n",
      "[TL] DenseLayer  model/output: 7 identity\n",
      "[TL] InputLayer  model/input: (128, 60, 80, 1)\n",
      "[TL] Conv2dLayer model/cnn1: shape:(5, 5, 1, 32) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer model/bn1: decay:0.900000 epsilon:0.000010 act:relu is_train:False\n",
      "[TL] PoolLayer   model/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] Conv2dLayer model/cnn2: shape:(5, 5, 32, 64) strides:(1, 1, 1, 1) pad:SAME act:identity\n",
      "[TL] BatchNormLayer model/bn2: decay:0.900000 epsilon:0.000010 act:relu is_train:False\n",
      "[TL] PoolLayer   model/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "[TL] FlattenLayer model/flatten: 19200\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] DenseLayer  model/relu1: 256 relu\n",
      "[TL]   skip DropoutLayer\n",
      "[TL] DenseLayer  model/output: 7 identity\n",
      "[TL]   param   0: model/cnn1/W_conv2d:0 (5, 5, 1, 32)      float16_ref\n",
      "[TL]   param   1: model/cnn1/b_conv2d:0 (32,)              float16_ref\n",
      "[TL]   param   2: model/bn1/beta:0     (32,)              float16_ref\n",
      "[TL]   param   3: model/bn1/gamma:0    (32,)              float16_ref\n",
      "[TL]   param   4: model/bn1/moving_mean:0 (32,)              float16_ref\n",
      "[TL]   param   5: model/bn1/moving_variance:0 (32,)              float16_ref\n",
      "[TL]   param   6: model/cnn2/W_conv2d:0 (5, 5, 32, 64)     float16_ref\n",
      "[TL]   param   7: model/cnn2/b_conv2d:0 (64,)              float16_ref\n",
      "[TL]   param   8: model/bn2/beta:0     (64,)              float16_ref\n",
      "[TL]   param   9: model/bn2/gamma:0    (64,)              float16_ref\n",
      "[TL]   param  10: model/bn2/moving_mean:0 (64,)              float16_ref\n",
      "[TL]   param  11: model/bn2/moving_variance:0 (64,)              float16_ref\n",
      "[TL]   param  12: model/relu1/W:0      (19200, 256)       float16_ref\n",
      "[TL]   param  13: model/relu1/b:0      (256,)             float16_ref\n",
      "[TL]   param  14: model/output/W:0     (256, 7)           float16_ref\n",
      "[TL]   param  15: model/output/b:0     (7,)               float16_ref\n",
      "[TL]   num of params: 4969735\n"
     ]
    }
   ],
   "source": [
    "# define inferences\n",
    "net_train = model(x, is_train=True, reuse=False)\n",
    "net_test = model(x, is_train=False, reuse=True)\n",
    "\n",
    "net_train.print_params(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost for training\n",
    "y = net_train.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='xentropy')\n",
    "\n",
    "# cost and accuracy for evalution\n",
    "y2 = net_test.outputs\n",
    "cost_test = tl.cost.cross_entropy(y2, y_, name='xentropy2')\n",
    "correct_prediction = tf.equal(tf.argmax(y2, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, LayersConfig.tf_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   [*] geting variables with model\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer\n",
    "train_params = tl.layers.get_variables_with_name('model', train_only=True, printable=False)\n",
    "train_op = tf.train.AdamOptimizer(\n",
    "    learning_rate=0.0001,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    # epsilon=1e-08,    # for float32 as default\n",
    "    epsilon=1e-4,  # for float16, see https://stackoverflow.com/questions/42064941/tensorflow-float16-support-is-broken\n",
    "    use_locking=False).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all variables in the session\n",
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 150 took 15.568545s\n",
      "   train loss: 1.121951\n",
      "   train acc: 0.690374\n",
      "   val loss: 1.427595\n",
      "   val acc: 0.686756\n",
      "Epoch 2 of 150 took 14.200024s\n",
      "   train loss: 0.803941\n",
      "   train acc: 0.690890\n",
      "   val loss: 0.912063\n",
      "   val acc: 0.656622\n",
      "Epoch 3 of 150 took 14.396577s\n",
      "   train loss: 0.812311\n",
      "   train acc: 0.722288\n",
      "   val loss: 0.882580\n",
      "   val acc: 0.672619\n",
      "Epoch 4 of 150 took 14.411571s\n",
      "   train loss: 0.756841\n",
      "   train acc: 0.742998\n",
      "   val loss: 0.842913\n",
      "   val acc: 0.718006\n",
      "Epoch 5 of 150 took 14.430835s\n",
      "   train loss: 0.700932\n",
      "   train acc: 0.751253\n",
      "   val loss: 0.797154\n",
      "   val acc: 0.732887\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "n_epoch = 150\n",
    "print_freq = 1\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
    "        sess.run(train_op, feed_dict={x: X_train_a, y_: y_train_a})\n",
    "\n",
    "    if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
    "        print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, time.time() - start_time))\n",
    "        train_loss, train_acc, n_batch = 0, 0, 0\n",
    "        for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
    "            err, ac = sess.run([cost_test, acc], feed_dict={x: X_train_a, y_: y_train_a})\n",
    "            train_loss += err\n",
    "            train_acc += ac\n",
    "            n_batch += 1\n",
    "        print(\"   train loss: %f\" % (train_loss / n_batch))\n",
    "        print(\"   train acc: %f\" % (train_acc / n_batch))\n",
    "        val_loss, val_acc, n_batch = 0, 0, 0\n",
    "        for X_val_a, y_val_a in tl.iterate.minibatches(X_val, y_val, batch_size, shuffle=True):\n",
    "            err, ac = sess.run([cost_test, acc], feed_dict={x: X_val_a, y_: y_val_a})\n",
    "            val_loss += err\n",
    "            val_acc += ac\n",
    "            n_batch += 1\n",
    "        print(\"   val loss: %f\" % (val_loss / n_batch))\n",
    "        print(\"   val acc: %f\" % (val_acc / n_batch))\n",
    "        \n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test loss: 0.721535\n",
      "   test acc: 0.746817\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, n_batch = 0, 0, 0\n",
    "for X_test_a, y_test_a in tl.iterate.minibatches(X_test, y_test, batch_size, shuffle=True):\n",
    "    err, ac = sess.run([cost_test, acc], feed_dict={x: X_test_a, y_: y_test_a})\n",
    "    test_loss += err\n",
    "    test_acc += ac\n",
    "    n_batch += 1\n",
    "print(\"   test loss: %f\" % (test_loss / n_batch))\n",
    "print(\"   test acc: %f\" % (test_acc / n_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model2d.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(net_train.all_params, name='model2d.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] Load model2d.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.core.DenseLayer at 0x1298110af60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.load_and_assign_npz(sess=sess, name='model2d.npz', network=net_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling TensorRider Using the Generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython import display\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import socket\n",
    "import threading\n",
    "from time import ctime,sleep\n",
    "import string\n",
    "\n",
    "remoteImage = np.array([])\n",
    "stream = urllib.request.urlopen('http://192.168.73.73:8080/?action=stream&ignored.mjpg')\n",
    "bytes = bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Refreshing_Thread():\n",
    "    global remoteImage\n",
    "    global stream\n",
    "    global bytes\n",
    "    while True:\n",
    "        bytes += stream.read(1024)\n",
    "        a = bytes.find(b'\\xff\\xd8')\n",
    "        b = bytes.find(b'\\xff\\xd9')\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = bytes[a:b+2]\n",
    "            bytes = bytes[b+2:]\n",
    "            i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            i = rgb2mono(i)\n",
    "            remoteImage = i.reshape((1,60,80,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Controlling_Thread():\n",
    "    global remoteImage\n",
    "    addr=('192.168.73.73',51423)\n",
    "    s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)\n",
    "    while True:\n",
    "        direction = tl.utils.predict(sess, net_test, remoteImage, rx, y_op, batch_size=None)\n",
    "        msgCtrl_Udp = str(25) + \",\" + str((direction[0] - 3) * 15)\n",
    "#         print(msgCtrl_Udp)\n",
    "        s.sendto(msgCtrl_Udp.encode('utf-8'), addr)\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "RefreshImageThread = threading.Thread(target = Image_Refreshing_Thread)\n",
    "RefreshImageThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1361, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _run_fn\n",
      "    target_list, status, run_metadata)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype half and shape [128,60,80,1]\n",
      "\t [[Node: Placeholder = Placeholder[dtype=DT_HALF, shape=[128,60,80,1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
      "\t [[Node: model/output/Identity/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_163_model/output/Identity\", tensor_type=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-635de047d758>\", line 6, in Controlling_Thread\n",
      "    direction = tl.utils.predict(sess, net_test, remoteImage, rx, y_op, batch_size=None)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\", line 315, in predict\n",
      "    return sess.run(y_op, feed_dict=feed_dict)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 905, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1137, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1355, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1374, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype half and shape [128,60,80,1]\n",
      "\t [[Node: Placeholder = Placeholder[dtype=DT_HALF, shape=[128,60,80,1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
      "\t [[Node: model/output/Identity/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_163_model/output/Identity\", tensor_type=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Caused by op 'Placeholder', defined at:\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 760, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-c79c3492e094>\", line 3, in <module>\n",
      "    x = tf.placeholder(LayersConfig.tf_dtype, shape=[batch_size, 60, 80, 1])\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1746, in placeholder\n",
      "    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4026, in _placeholder\n",
      "    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype half and shape [128,60,80,1]\n",
      "\t [[Node: Placeholder = Placeholder[dtype=DT_HALF, shape=[128,60,80,1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
      "\t [[Node: model/output/Identity/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_163_model/output/Identity\", tensor_type=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ControllingThread = threading.Thread(target = Controlling_Thread)\n",
    "ControllingThread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
