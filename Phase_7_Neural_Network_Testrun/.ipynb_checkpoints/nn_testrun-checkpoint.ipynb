{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from skimage import io\n",
    "# from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2mono(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    # mono = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    mono = 0.5 * r + 0.25 * g + 0.25 * b\n",
    "    return mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataArrays(iterator):\n",
    "    X = np.zeros(19200)\n",
    "    y = np.zeros(1)\n",
    "    recordCounter = 0;\n",
    "\n",
    "    for string_record in iterator:\n",
    "        recordCounter += 1\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        imageString = (example.features.feature['image'].bytes_list.value[0])\n",
    "        label = (example.features.feature['label'].int64_list.value[0])\n",
    "\n",
    "        image = np.fromstring(imageString, dtype=np.uint8)\n",
    "        image = image.reshape((120, 160, 3))\n",
    "        image = rgb2mono(image)\n",
    "        image = image.reshape((19200))\n",
    "\n",
    "        X = np.vstack((X,image))\n",
    "        y = np.append(y,label)\n",
    "        if recordCounter % 100 == 0:\n",
    "            print(recordCounter)\n",
    "\n",
    "    y = y.reshape((recordCounter + 1,))\n",
    "    y = np.floor(y / 6) #Downsampling\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator = tf.python_io.tf_record_iterator(path=\"train.tfrecords\")\n",
    "valIterator = tf.python_io.tf_record_iterator(path=\"val.tfrecords\")\n",
    "testIterator = tf.python_io.tf_record_iterator(path=\"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "Val...\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Test...\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train...\")\n",
    "X_train, y_train = prepareDataArrays(trainIterator)\n",
    "print(\"Val...\")\n",
    "X_val, y_val = prepareDataArrays(valIterator)\n",
    "print(\"Test...\")\n",
    "X_test, y_test = prepareDataArrays(testIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 19200], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input: (?, 19200)\n",
      "[TL] DropoutLayer drop1: keep:0.800000 is_fix:False\n",
      "[TL] DenseLayer  relu1: 3200 relu\n",
      "[TL] DropoutLayer drop2: keep:0.500000 is_fix:False\n",
      "[TL] DenseLayer  relu2: 3200 relu\n",
      "[TL] DropoutLayer drop3: keep:0.500000 is_fix:False\n",
      "[TL] DenseLayer  output: 13 identity\n"
     ]
    }
   ],
   "source": [
    "network = tl.layers.InputLayer(x, name='input')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, 3200, tf.nn.relu, name='relu1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, 3200, tf.nn.relu, name='relu2')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "network = tl.layers.DenseLayer(network, n_units=13, act=tf.identity, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost, var_list=train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   param   0: relu1/W:0            (19200, 3200)      float32_ref (mean: -1.2768404303642455e-05, median: -1.872119537438266e-05, std: 0.08796688914299011)   \n",
      "[TL]   param   1: relu1/b:0            (3200,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (3200, 3200)       float32_ref (mean: 1.730628173390869e-05, median: 2.6748539312393405e-05, std: 0.08796454966068268)   \n",
      "[TL]   param   3: relu2/b:0            (3200,)            float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: output/W:0           (3200, 13)         float32_ref (mean: -0.00021717275376431644, median: -0.0003416336257942021, std: 0.08802831918001175)   \n",
      "[TL]   param   5: output/b:0           (13,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 71728013\n"
     ]
    }
   ],
   "source": [
    "network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL]   layer   0: drop1/mul:0          (?, 19200)         float32\n",
      "[TL]   layer   1: relu1/Relu:0         (?, 3200)          float32\n",
      "[TL]   layer   2: drop2/mul:0          (?, 3200)          float32\n",
      "[TL]   layer   3: relu2/Relu:0         (?, 3200)          float32\n",
      "[TL]   layer   4: drop3/mul:0          (?, 3200)          float32\n",
      "[TL]   layer   5: output/Identity:0    (?, 13)            float32\n"
     ]
    }
   ],
   "source": [
    "network.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 5.525784s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 5 of 500 took 3.161909s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 10 of 500 took 3.099270s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 15 of 500 took 3.151257s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 20 of 500 took 3.141151s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 25 of 500 took 3.145578s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 30 of 500 took 3.157490s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 35 of 500 took 3.143686s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 40 of 500 took 3.162637s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 45 of 500 took 3.175105s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 50 of 500 took 3.181088s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 55 of 500 took 3.174674s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 60 of 500 took 3.178191s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 65 of 500 took 3.161407s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 70 of 500 took 3.171687s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 75 of 500 took 3.138019s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 80 of 500 took 3.146486s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 85 of 500 took 3.168506s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 90 of 500 took 3.159968s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 95 of 500 took 3.170503s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 100 of 500 took 3.147875s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 105 of 500 took 3.172188s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 110 of 500 took 3.166039s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 115 of 500 took 3.176710s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 120 of 500 took 3.147937s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 125 of 500 took 3.144403s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 130 of 500 took 3.166957s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 135 of 500 took 3.176447s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 140 of 500 took 3.173479s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 145 of 500 took 3.134485s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 150 of 500 took 3.196246s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 155 of 500 took 3.134643s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 160 of 500 took 3.130361s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 165 of 500 took 3.129297s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 170 of 500 took 3.118436s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 175 of 500 took 3.179586s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 180 of 500 took 3.166021s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 185 of 500 took 3.154961s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 190 of 500 took 3.236821s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 195 of 500 took 3.126803s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 200 of 500 took 3.128835s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 205 of 500 took 3.119400s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 210 of 500 took 3.159435s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 215 of 500 took 3.097802s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 220 of 500 took 3.104779s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 225 of 500 took 3.128994s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 230 of 500 took 3.248367s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 235 of 500 took 3.153032s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 240 of 500 took 3.128411s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 245 of 500 took 3.153888s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 250 of 500 took 3.151011s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.382000\n",
      "[TL] Epoch 255 of 500 took 3.162509s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 260 of 500 took 3.153591s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 265 of 500 took 3.127700s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 270 of 500 took 3.138553s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n",
      "[TL] Epoch 275 of 500 took 3.167271s\n",
      "[TL]    val loss: nan\n",
      "[TL]    val acc: 0.383000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-665d81707bd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tl.utils.fit(\n\u001b[1;32m----> 2\u001b[1;33m     sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=200, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(sess, network, train_op, cost, X_train, y_train, x, y_, acc, batch_size, n_epoch, print_freq, X_val, y_val, eval_train, tensorboard, tensorboard_epoch_freq, tensorboard_weight_histograms, tensorboard_graph_vis)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_drop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# enable noise layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mloss_ep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mn_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=200, n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (19200, 1) for Tensor 'x:0', which has shape '(?, 19200)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f3afcc0fb158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorlayer\\utils.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(sess, network, acc, X_test, y_test, x, y_, batch_size, cost)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   test loss: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   test acc: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# logging.info(\"   test acc: %f\" % np.mean(y_test == sess.run(y_op,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1113\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1114\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (19200, 1) for Tensor 'x:0', which has shape '(?, 19200)'"
     ]
    }
   ],
   "source": [
    "tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TL] [*] model.npz saved\n"
     ]
    }
   ],
   "source": [
    "tl.files.save_npz(network.all_params, name='model.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
